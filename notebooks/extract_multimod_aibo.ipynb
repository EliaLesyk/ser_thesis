{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8310e528-6ac0-434d-929f-cce9e84845e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "#import torchaudio\n",
    "#import requests\n",
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "#import IPython\n",
    "#import gc\n",
    "import numpy as np\n",
    "\n",
    "from os.path import isfile, join\n",
    "from scipy.io.wavfile import write, read\n",
    "from scipy.stats import kurtosis, skew\n",
    "#from datasets import load_dataset\n",
    "#from tqdm import tqdm\n",
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model, Wav2Vec2ForPreTraining, Wav2Vec2ForXVector\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import _compute_mask_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec25e3fd-3ab5-4ef9-a74d-d297161016de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#home_path = '/home/hpc/iwi5/iwi5055h/'\n",
    "home_path = ''\n",
    "aibo_path = home_path + \"data/AIBO/\"\n",
    "save_path = aibo_path + \"wav2vec/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8c461d-024b-43a3-92af-bc812b0f6c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_mode = 'base'\n",
    "model_mode = 'xlsr'\n",
    "#model_mode = 'xlsr-de'\n",
    "#model_mode = 'xvec'\n",
    "# 'xlsr' | 'base' | 'xvec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e58205a-b56e-4eb4-a6e6-386cff1783c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wav2Vec_Models(file, model_name='xvec', plot=False, cuda=False):\n",
    "\n",
    "    try:\n",
    "        fs, audio=read(file)   \n",
    "        audio=(audio - np.mean(audio))/max(audio)\n",
    "       \n",
    "        device='cpu'\n",
    "        if cuda:\n",
    "            device='cuda'\n",
    "       \n",
    "        #sampling_rate = fs\n",
    "       \n",
    "        if model_name=='xlsr':\n",
    "            feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\")\n",
    "            model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\").to(device)\n",
    "            #model_proj = Wav2Vec2ForPreTraining.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\").to(device)\n",
    "        elif model_name=='xlsr-de':\n",
    "            feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-large-xlsr-53-german\")\n",
    "            model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-large-xlsr-53-german\").to(device)\n",
    "        elif model_name=='base':\n",
    "            feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-base-960h\")   \n",
    "            model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\").to(device)\n",
    "            #model_proj = Wav2Vec2ForPreTraining.from_pretrained(\"facebook/wav2vec2-base-960h\").to(device)\n",
    "        elif model_name=='xvec':\n",
    "            feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"anton-l/wav2vec2-base-superb-sv\")        \n",
    "            #feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/wav2vec2-base-superb-er\")        \n",
    "            model = Wav2Vec2ForXVector.from_pretrained(\"anton-l/wav2vec2-base-superb-sv\").to(device)\n",
    "            #model_proj = Wav2Vec2ForPreTraining.from_pretrained(\"anton-l/wav2vec2-base-superb-sv\").to(device)\n",
    "   \n",
    "        # audio file is decoded on the fly\n",
    "        input_values = feature_extractor(np.array(audio, dtype=float), sampling_rate=fs, return_tensors=\"pt\", padding=True).to(device).input_values\n",
    "        input_values_all = feature_extractor(np.array(audio, dtype=float), sampling_rate=fs, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "        # compute masked indices\n",
    "        batch_size, raw_sequence_length = input_values.shape\n",
    "        sequence_length = model._get_feat_extract_output_lengths(raw_sequence_length)\n",
    "        mask_time_indices = _compute_mask_indices((batch_size, sequence_length), mask_prob=0.2, mask_length=2)\n",
    "        mask_time_indices = torch.tensor(mask_time_indices, device=input_values.device, dtype=torch.long)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "\n",
    "            tmp = model(**input_values_all.to(device))\n",
    "            #tmp_proj=model_proj(input_values.to(device), mask_time_indices=mask_time_indices.to(device) )\n",
    "            if model_name=='xvec':\n",
    "                last_hidden_states = tmp.embeddings.cpu()\n",
    "                #last_hidden_states=np.hstack((last_hiddens_avg,last_hiddens_std,last_hiddens_skew,last_hiddens_kurt,last_hiddens_min,last_hiddens_max))\n",
    "\n",
    "                features = tmp.logits.cpu()\n",
    "                #features = np.hstack((features,features_std,features_skew,features_kurt,features_min,features_max))\n",
    "\n",
    "                #last_hiddens_avg=np.array(torch.mean(tmp_proj.projected_states, dim=1).cpu())\n",
    "                #last_hiddens_std=np.array(torch.std(tmp_proj.projected_states, dim=1).cpu())\n",
    "                #last_hiddens_skew=skew(np.array(tmp_proj.projected_states.cpu()), axis=1)\n",
    "                #last_hiddens_kurt=kurtosis(np.array(tmp_proj.projected_states.cpu()), axis=1)\n",
    "                #last_hiddens_min=np.array(torch.min(tmp_proj.projected_states, dim=1)[0].cpu())\n",
    "                #last_hiddens_max=np.array(torch.max(tmp_proj.projected_states, dim=1)[0].cpu())\n",
    "                #last_hiddens_proj=np.hstack((last_hiddens_avg,last_hiddens_std,last_hiddens_skew,last_hiddens_kurt,last_hiddens_min,last_hiddens_max))\n",
    "\n",
    "                #features_avg=np.array(torch.mean(tmp_proj.projected_quantized_states, dim=1).cpu())\n",
    "                #features_std=np.array(torch.std(tmp_proj.projected_quantized_states, dim=1).cpu())\n",
    "                #features_skew=skew(np.array(tmp_proj.projected_quantized_states.cpu()), axis=1)\n",
    "                #features_kurt=kurtosis(np.array(tmp_proj.projected_quantized_states.cpu()), axis=1)\n",
    "                #features_min=np.array(torch.min(tmp_proj.projected_quantized_states, dim=1)[0].cpu())\n",
    "                #features_max=np.array(torch.max(tmp_proj.projected_quantized_states, dim=1)[0].cpu())\n",
    "                #features_proj = np.hstack((features_avg,features_std,features_skew,features_kurt,features_min,features_max))\n",
    "\n",
    "            else:\n",
    "                last_hiddens_avg=np.array(torch.mean(tmp.last_hidden_state, dim=1).cpu())\n",
    "                last_hiddens_std=np.array(torch.std(tmp.last_hidden_state, dim=1).cpu())\n",
    "                last_hiddens_skew=skew(np.array(tmp.last_hidden_state.cpu()), axis=1)\n",
    "                last_hiddens_kurt=kurtosis(np.array(tmp.last_hidden_state.cpu()), axis=1)\n",
    "                last_hiddens_min=np.array(torch.min(tmp.last_hidden_state, dim=1)[0].cpu())\n",
    "                last_hiddens_max=np.array(torch.max(tmp.last_hidden_state, dim=1)[0].cpu())\n",
    "\n",
    "                last_hidden_states=np.hstack((last_hiddens_avg,last_hiddens_std,last_hiddens_skew,last_hiddens_kurt,last_hiddens_min,last_hiddens_max))\n",
    "\n",
    "                features_avg=np.array(torch.mean(tmp.extract_features, dim=1).cpu())\n",
    "                features_std=np.array(torch.std(tmp.extract_features, dim=1).cpu())\n",
    "                features_skew=skew(np.array(tmp.extract_features.cpu()), axis=1)\n",
    "                features_kurt=kurtosis(np.array(tmp.extract_features.cpu()), axis=1)\n",
    "                features_min=np.array(torch.min(tmp.extract_features, dim=1)[0].cpu())\n",
    "                features_max=np.array(torch.max(tmp.extract_features, dim=1)[0].cpu())\n",
    "\n",
    "                features = np.hstack((features_avg,features_std,features_skew,features_kurt,features_min,features_max))\n",
    "\n",
    "                #last_hiddens_avg=np.array(torch.mean(tmp_proj.projected_states, dim=1).cpu())\n",
    "                #last_hiddens_std=np.array(torch.std(tmp_proj.projected_states, dim=1).cpu())\n",
    "                #last_hiddens_skew=skew(np.array(tmp_proj.projected_states.cpu()), axis=1)\n",
    "                #last_hiddens_kurt=kurtosis(np.array(tmp_proj.projected_states.cpu()), axis=1)\n",
    "                #last_hiddens_min=np.array(torch.min(tmp_proj.projected_states, dim=1)[0].cpu())\n",
    "                #last_hiddens_max=np.array(torch.max(tmp_proj.projected_states, dim=1)[0].cpu())\n",
    "                #last_hiddens_proj=np.hstack((last_hiddens_avg,last_hiddens_std,last_hiddens_skew,last_hiddens_kurt,last_hiddens_min,last_hiddens_max))\n",
    "\n",
    "                #features_avg=np.array(torch.mean(tmp_proj.projected_quantized_states, dim=1).cpu())\n",
    "                #features_std=np.array(torch.std(tmp_proj.projected_quantized_states, dim=1).cpu())\n",
    "                #features_skew=skew(np.array(tmp_proj.projected_quantized_states.cpu()), axis=1)\n",
    "                #features_kurt=kurtosis(np.array(tmp_proj.projected_quantized_states.cpu()), axis=1)\n",
    "                #features_min=np.array(torch.min(tmp_proj.projected_quantized_states, dim=1)[0].cpu())\n",
    "                #features_max=np.array(torch.max(tmp_proj.projected_quantized_states, dim=1)[0].cpu())\n",
    "                #features_proj = np.hstack((features_avg,features_std,features_skew,features_kurt,features_min,features_max))\n",
    "\n",
    "        return features[0], last_hidden_states[0]\n",
    "    except:\n",
    "        print('sequence not long enough')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d0405c-6d25-4273-be57-34c9fc79120a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Testing a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8c6f9a-be14-4b2e-8858-bf7463fa77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = 'data/AIBO/wav/Mont_01_053_00.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a96da571-3292-4d91-a519-5f8b03a6c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xlsr'\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db72e6ec-ed2e-4122-b6d3-27eb2688145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2Model: ['quantizer.weight_proj.weight', 'project_q.weight', 'quantizer.codevectors', 'project_q.bias', 'project_hid.bias', 'quantizer.weight_proj.bias', 'project_hid.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "fs, audio=read(test_file)   \n",
    "audio=(audio-np.mean(audio))/max(audio)\n",
    "sampling_rate = fs\n",
    "\n",
    "if model_name=='xlsr':\n",
    "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\")\n",
    "    model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\").to(device)\n",
    "    #model_proj = Wav2Vec2ForPreTraining.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\").to(device)\n",
    "#elif model_name=='base':\n",
    " #   feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-base-960h\")   \n",
    "  #  model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\").to(device)\n",
    "   # #model_proj = Wav2Vec2ForPreTraining.from_pretrained(\"facebook/wav2vec2-base-960h\").to(device)\n",
    "#elif model_name=='xvec':\n",
    " #   feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"anton-l/wav2vec2-base-superb-sv\")        \n",
    "  #  model = Wav2Vec2ForXVector.from_pretrained(\"anton-l/wav2vec2-base-superb-sv\").to(device)\n",
    "    #feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/wav2vec2-base-superb-er\")  # size mistmatch        \n",
    "    #model = Wav2Vec2ForXVector.from_pretrained(\"superb/wav2vec2-base-superb-er\").to(device)\n",
    "    #model_proj = Wav2Vec2ForPreTraining.from_pretrained(\"anton-l/wav2vec2-base-superb-sv\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb85582c-12db-4939-8d67-7b7cf7d583c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    else:\\n        last_hiddens_avg=np.array(torch.mean(tmp.last_hidden_state, dim=1).cpu())\\n        last_hiddens_std=np.array(torch.std(tmp.last_hidden_state, dim=1).cpu())\\n        last_hiddens_skew=skew(np.array(tmp.last_hidden_state.cpu()), axis=1)\\n        last_hiddens_kurt=kurtosis(np.array(tmp.last_hidden_state.cpu()), axis=1)\\n        last_hiddens_min=np.array(torch.min(tmp.last_hidden_state, dim=1)[0].cpu())\\n        last_hiddens_max=np.array(torch.max(tmp.last_hidden_state, dim=1)[0].cpu())\\n\\n        last_hidden_states=np.hstack((last_hiddens_avg,last_hiddens_std,last_hiddens_skew,last_hiddens_kurt,last_hiddens_min,last_hiddens_max))\\n\\n        features_avg=np.array(torch.mean(tmp.extract_features, dim=1).cpu())\\n        features_std=np.array(torch.std(tmp.extract_features, dim=1).cpu())\\n        features_skew=skew(np.array(tmp.extract_features.cpu()), axis=1)\\n        features_kurt=kurtosis(np.array(tmp.extract_features.cpu()), axis=1)\\n        features_min=np.array(torch.min(tmp.extract_features, dim=1)[0].cpu())\\n        features_max=np.array(torch.max(tmp.extract_features, dim=1)[0].cpu())\\n\\n        features = np.hstack((features_avg,features_std,features_skew,features_kurt,features_min,features_max))\\n\\n        #last_hiddens_avg=np.array(torch.mean(tmp_proj.projected_states, dim=1).cpu())\\n        #last_hiddens_std=np.array(torch.std(tmp_proj.projected_states, dim=1).cpu())\\n        #last_hiddens_skew=skew(np.array(tmp_proj.projected_states.cpu()), axis=1)\\n        #last_hiddens_kurt=kurtosis(np.array(tmp_proj.projected_states.cpu()), axis=1)\\n        #last_hiddens_min=np.array(torch.min(tmp_proj.projected_states, dim=1)[0].cpu())\\n        #last_hiddens_max=np.array(torch.max(tmp_proj.projected_states, dim=1)[0].cpu())\\n        #last_hiddens_proj=np.hstack((last_hiddens_avg,last_hiddens_std,last_hiddens_skew,last_hiddens_kurt,last_hiddens_min,last_hiddens_max))\\n\\n        #features_avg=np.array(torch.mean(tmp_proj.projected_quantized_states, dim=1).cpu())\\n        #features_std=np.array(torch.std(tmp_proj.projected_quantized_states, dim=1).cpu())\\n        #features_skew=skew(np.array(tmp_proj.projected_quantized_states.cpu()), axis=1)\\n        #features_kurt=kurtosis(np.array(tmp_proj.projected_quantized_states.cpu()), axis=1)\\n        #features_min=np.array(torch.min(tmp_proj.projected_quantized_states, dim=1)[0].cpu())\\n        #features_max=np.array(torch.max(tmp_proj.projected_quantized_states, dim=1)[0].cpu())\\n        #features_proj = np.hstack((features_avg,features_std,features_skew,features_kurt,features_min,features_max))\\n\\nprint(features[0], last_hidden_states[0])\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# audio file is decoded on the fly\n",
    "input_values = feature_extractor(np.array(audio, dtype=float), sampling_rate=fs, return_tensors=\"pt\", padding=True).to(device).input_values\n",
    "#input_values_all = feature_extractor(np.array(audio, dtype=float), sampling_rate=fs, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# compute masked indices\n",
    "#batch_size, raw_sequence_length = input_values.shape\n",
    "#sequence_length = model._get_feat_extract_output_lengths(raw_sequence_length)\n",
    "#mask_time_indices = _compute_mask_indices((batch_size, sequence_length), mask_prob=0.2, mask_length=2)\n",
    "#mask_time_indices = torch.tensor(mask_time_indices, device=input_values.device, dtype=torch.long)\n",
    "\n",
    "#with torch.inference_mode():\n",
    "           \n",
    " #   tmp = model(**input_values_all.to(device))\n",
    "    #tmp_proj=model_proj(input_values.to(device), mask_time_indices=mask_time_indices.to(device) )\n",
    "  #  if model_name=='xvec':\n",
    "   #     last_hidden_states = tmp.embeddings.cpu()\n",
    "        #last_hidden_states=np.hstack((last_hiddens_avg,last_hiddens_std,last_hiddens_skew,last_hiddens_kurt,last_hiddens_min,last_hiddens_max))\n",
    "\n",
    "    #    features = tmp.logits.cpu()\n",
    "        #features = np.hstack((features,features_std,features_skew,features_kurt,features_min,features_max))\n",
    "\n",
    "        #last_hiddens_avg=np.array(torch.mean(tmp_proj.projected_states, dim=1).cpu())\n",
    "        #last_hiddens_std=np.array(torch.std(tmp_proj.projected_states, dim=1).cpu())\n",
    "        #last_hiddens_skew=skew(np.array(tmp_proj.projected_states.cpu()), axis=1)\n",
    "        #last_hiddens_kurt=kurtosis(np.array(tmp_proj.projected_states.cpu()), axis=1)\n",
    "        #last_hiddens_min=np.array(torch.min(tmp_proj.projected_states, dim=1)[0].cpu())\n",
    "        #last_hiddens_max=np.array(torch.max(tmp_proj.projected_states, dim=1)[0].cpu())\n",
    "        #last_hiddens_proj=np.hstack((last_hiddens_avg,last_hiddens_std,last_hiddens_skew,last_hiddens_kurt,last_hiddens_min,last_hiddens_max))\n",
    "\n",
    "        #features_avg=np.array(torch.mean(tmp_proj.projected_quantized_states, dim=1).cpu())\n",
    "        #features_std=np.array(torch.std(tmp_proj.projected_quantized_states, dim=1).cpu())\n",
    "        #features_skew=skew(np.array(tmp_proj.projected_quantized_states.cpu()), axis=1)\n",
    "        #features_kurt=kurtosis(np.array(tmp_proj.projected_quantized_states.cpu()), axis=1)\n",
    "        #features_min=np.array(torch.min(tmp_proj.projected_quantized_states, dim=1)[0].cpu())\n",
    "        #features_max=np.array(torch.max(tmp_proj.projected_quantized_states, dim=1)[0].cpu())\n",
    "        #features_proj = np.hstack((features_avg,features_std,features_skew,features_kurt,features_min,features_max))\n",
    "'''\n",
    "    else:\n",
    "        last_hiddens_avg=np.array(torch.mean(tmp.last_hidden_state, dim=1).cpu())\n",
    "        last_hiddens_std=np.array(torch.std(tmp.last_hidden_state, dim=1).cpu())\n",
    "        last_hiddens_skew=skew(np.array(tmp.last_hidden_state.cpu()), axis=1)\n",
    "        last_hiddens_kurt=kurtosis(np.array(tmp.last_hidden_state.cpu()), axis=1)\n",
    "        last_hiddens_min=np.array(torch.min(tmp.last_hidden_state, dim=1)[0].cpu())\n",
    "        last_hiddens_max=np.array(torch.max(tmp.last_hidden_state, dim=1)[0].cpu())\n",
    "\n",
    "        last_hidden_states=np.hstack((last_hiddens_avg,last_hiddens_std,last_hiddens_skew,last_hiddens_kurt,last_hiddens_min,last_hiddens_max))\n",
    "\n",
    "        features_avg=np.array(torch.mean(tmp.extract_features, dim=1).cpu())\n",
    "        features_std=np.array(torch.std(tmp.extract_features, dim=1).cpu())\n",
    "        features_skew=skew(np.array(tmp.extract_features.cpu()), axis=1)\n",
    "        features_kurt=kurtosis(np.array(tmp.extract_features.cpu()), axis=1)\n",
    "        features_min=np.array(torch.min(tmp.extract_features, dim=1)[0].cpu())\n",
    "        features_max=np.array(torch.max(tmp.extract_features, dim=1)[0].cpu())\n",
    "\n",
    "        features = np.hstack((features_avg,features_std,features_skew,features_kurt,features_min,features_max))\n",
    "\n",
    "        #last_hiddens_avg=np.array(torch.mean(tmp_proj.projected_states, dim=1).cpu())\n",
    "        #last_hiddens_std=np.array(torch.std(tmp_proj.projected_states, dim=1).cpu())\n",
    "        #last_hiddens_skew=skew(np.array(tmp_proj.projected_states.cpu()), axis=1)\n",
    "        #last_hiddens_kurt=kurtosis(np.array(tmp_proj.projected_states.cpu()), axis=1)\n",
    "        #last_hiddens_min=np.array(torch.min(tmp_proj.projected_states, dim=1)[0].cpu())\n",
    "        #last_hiddens_max=np.array(torch.max(tmp_proj.projected_states, dim=1)[0].cpu())\n",
    "        #last_hiddens_proj=np.hstack((last_hiddens_avg,last_hiddens_std,last_hiddens_skew,last_hiddens_kurt,last_hiddens_min,last_hiddens_max))\n",
    "\n",
    "        #features_avg=np.array(torch.mean(tmp_proj.projected_quantized_states, dim=1).cpu())\n",
    "        #features_std=np.array(torch.std(tmp_proj.projected_quantized_states, dim=1).cpu())\n",
    "        #features_skew=skew(np.array(tmp_proj.projected_quantized_states.cpu()), axis=1)\n",
    "        #features_kurt=kurtosis(np.array(tmp_proj.projected_quantized_states.cpu()), axis=1)\n",
    "        #features_min=np.array(torch.min(tmp_proj.projected_quantized_states, dim=1)[0].cpu())\n",
    "        #features_max=np.array(torch.max(tmp_proj.projected_quantized_states, dim=1)[0].cpu())\n",
    "        #features_proj = np.hstack((features_avg,features_std,features_skew,features_kurt,features_min,features_max))\n",
    "\n",
    "print(features[0], last_hidden_states[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885edf09-cdbf-472c-abfe-d1b209add853",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "219ba04e-0f90-47c5-a501-2b37e201249f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#text_file = open('data/AIBO/labels/chunk_labels_5cl_corpus.txt')\n",
    "text_file = open(home_path + 'data/AIBO/labels/chunk_labels_5cl_corpus.txt')\n",
    "file_content = text_file.read()\n",
    "#print(file_content)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "883c5cd5-6763-47c2-892d-555a8db4af6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##data_ = text_file.decode(\"utf-8\").split(\"\\r\\n\")\n",
    "data = file_content\n",
    "data = data.split(\"\\n\")\n",
    "for i in range(len(data)):\n",
    "      data[i] = data[i].replace('_', ' ').split(\" \")\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aae749f5-337e-46fa-a310-a75515277693",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame(data, columns=[\"source\", \"speaker\", \"n_rec\", \"num\", \"label\", \"percentage\"], index=None)\n",
    "labels_df['filename'] = labels_df.source + \"_\" + labels_df.speaker + \"_\" + labels_df.n_rec + \"_\" + labels_df.num\n",
    "file_path = aibo_path + \"wav/\"\n",
    "labels_df['path'] = file_path + labels_df['filename'] + \".wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "deac3cd4-d430-4402-a9f0-33acb4faeba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>speaker</th>\n",
       "      <th>n_rec</th>\n",
       "      <th>num</th>\n",
       "      <th>label</th>\n",
       "      <th>percentage</th>\n",
       "      <th>filename</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont</td>\n",
       "      <td>01</td>\n",
       "      <td>000</td>\n",
       "      <td>00</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>Mont_01_000_00</td>\n",
       "      <td>data/AIBO/wav/Mont_01_000_00.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mont</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>00</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>Mont_01_001_00</td>\n",
       "      <td>data/AIBO/wav/Mont_01_001_00.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mont</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>Mont_01_001_01</td>\n",
       "      <td>data/AIBO/wav/Mont_01_001_01.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mont</td>\n",
       "      <td>01</td>\n",
       "      <td>004</td>\n",
       "      <td>00</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Mont_01_004_00</td>\n",
       "      <td>data/AIBO/wav/Mont_01_004_00.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mont</td>\n",
       "      <td>01</td>\n",
       "      <td>005</td>\n",
       "      <td>00</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>Mont_01_005_00</td>\n",
       "      <td>data/AIBO/wav/Mont_01_005_00.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18212</th>\n",
       "      <td>Ohm</td>\n",
       "      <td>32</td>\n",
       "      <td>318</td>\n",
       "      <td>00</td>\n",
       "      <td>E</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Ohm_32_318_00</td>\n",
       "      <td>data/AIBO/wav/Ohm_32_318_00.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18213</th>\n",
       "      <td>Ohm</td>\n",
       "      <td>32</td>\n",
       "      <td>319</td>\n",
       "      <td>00</td>\n",
       "      <td>E</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Ohm_32_319_00</td>\n",
       "      <td>data/AIBO/wav/Ohm_32_319_00.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18214</th>\n",
       "      <td>Ohm</td>\n",
       "      <td>32</td>\n",
       "      <td>320</td>\n",
       "      <td>00</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Ohm_32_320_00</td>\n",
       "      <td>data/AIBO/wav/Ohm_32_320_00.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18215</th>\n",
       "      <td>Ohm</td>\n",
       "      <td>32</td>\n",
       "      <td>321</td>\n",
       "      <td>00</td>\n",
       "      <td>P</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Ohm_32_321_00</td>\n",
       "      <td>data/AIBO/wav/Ohm_32_321_00.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18216</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18217 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source speaker n_rec   num label percentage        filename  \\\n",
       "0       Mont      01   000    00     N          1  Mont_01_000_00   \n",
       "1       Mont      01   001    00     N          1  Mont_01_001_00   \n",
       "2       Mont      01   001    01     N          1  Mont_01_001_01   \n",
       "3       Mont      01   004    00     N        0.9  Mont_01_004_00   \n",
       "4       Mont      01   005    00     N          1  Mont_01_005_00   \n",
       "...      ...     ...   ...   ...   ...        ...             ...   \n",
       "18212    Ohm      32   318    00     E        0.4   Ohm_32_318_00   \n",
       "18213    Ohm      32   319    00     E        0.6   Ohm_32_319_00   \n",
       "18214    Ohm      32   320    00     N        0.9   Ohm_32_320_00   \n",
       "18215    Ohm      32   321    00     P        0.7   Ohm_32_321_00   \n",
       "18216           None  None  None  None       None             NaN   \n",
       "\n",
       "                                   path  \n",
       "0      data/AIBO/wav/Mont_01_000_00.wav  \n",
       "1      data/AIBO/wav/Mont_01_001_00.wav  \n",
       "2      data/AIBO/wav/Mont_01_001_01.wav  \n",
       "3      data/AIBO/wav/Mont_01_004_00.wav  \n",
       "4      data/AIBO/wav/Mont_01_005_00.wav  \n",
       "...                                 ...  \n",
       "18212   data/AIBO/wav/Ohm_32_318_00.wav  \n",
       "18213   data/AIBO/wav/Ohm_32_319_00.wav  \n",
       "18214   data/AIBO/wav/Ohm_32_320_00.wav  \n",
       "18215   data/AIBO/wav/Ohm_32_321_00.wav  \n",
       "18216                               NaN  \n",
       "\n",
       "[18217 rows x 8 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fd056575-d03f-442d-a8b2-11fb83952b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18217"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f9993560-6da4-4537-a12b-f9025dd7e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testdf = labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6e90fc8-833b-49b4-88de-2ed26afe1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testdf['spsource'] = testdf['source'] + testdf['speaker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fa8f855-c2e7-4cfb-84eb-28e0825604fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testdf.spsource.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33ce9a1e-3133-4a4f-a7ca-38a95769989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_file = \"data/AIBO/wav/Mont_01_007_00.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "359fceb6-8eb5-4793-ad9a-05c9bf353b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fs, audio = read(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43b5757d-f0e3-40b0-b81a-b32f22349890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a4a75b86-057f-4a4a-862c-21b675f1fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[\"speaker\"] = pd.to_numeric(labels_df[\"speaker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98073c8d-7f8a-4977-8dcf-f850d1cbd021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_df.speaker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "438b196b-21f5-48c5-8a6e-d928055b511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##labels_df.loc[labels_df.source =='Ohm', 'speaker'] = labels_df.speaker + 25\n",
    "# speaker 01 from Ohm or Mont should be treated equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1a1d5656-1852-4e24-b6ad-ecb537392639",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {'A': 0, 'E': 1, 'N': 2, 'P': 3, 'R': 4}\n",
    "labels_df['lb'] = labels_df['label'].map(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6d854e63-8470-428b-87be-08e43a35deda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>speaker</th>\n",
       "      <th>n_rec</th>\n",
       "      <th>num</th>\n",
       "      <th>label</th>\n",
       "      <th>percentage</th>\n",
       "      <th>filename</th>\n",
       "      <th>path</th>\n",
       "      <th>lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont</td>\n",
       "      <td>1.0</td>\n",
       "      <td>000</td>\n",
       "      <td>00</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>Mont_01_000_00</td>\n",
       "      <td>data/AIBO/wav/Mont_01_000_00.wav</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mont</td>\n",
       "      <td>1.0</td>\n",
       "      <td>001</td>\n",
       "      <td>00</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>Mont_01_001_00</td>\n",
       "      <td>data/AIBO/wav/Mont_01_001_00.wav</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mont</td>\n",
       "      <td>1.0</td>\n",
       "      <td>001</td>\n",
       "      <td>01</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>Mont_01_001_01</td>\n",
       "      <td>data/AIBO/wav/Mont_01_001_01.wav</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mont</td>\n",
       "      <td>1.0</td>\n",
       "      <td>004</td>\n",
       "      <td>00</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Mont_01_004_00</td>\n",
       "      <td>data/AIBO/wav/Mont_01_004_00.wav</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mont</td>\n",
       "      <td>1.0</td>\n",
       "      <td>005</td>\n",
       "      <td>00</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>Mont_01_005_00</td>\n",
       "      <td>data/AIBO/wav/Mont_01_005_00.wav</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18212</th>\n",
       "      <td>Ohm</td>\n",
       "      <td>32.0</td>\n",
       "      <td>318</td>\n",
       "      <td>00</td>\n",
       "      <td>E</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Ohm_32_318_00</td>\n",
       "      <td>data/AIBO/wav/Ohm_32_318_00.wav</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18213</th>\n",
       "      <td>Ohm</td>\n",
       "      <td>32.0</td>\n",
       "      <td>319</td>\n",
       "      <td>00</td>\n",
       "      <td>E</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Ohm_32_319_00</td>\n",
       "      <td>data/AIBO/wav/Ohm_32_319_00.wav</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18214</th>\n",
       "      <td>Ohm</td>\n",
       "      <td>32.0</td>\n",
       "      <td>320</td>\n",
       "      <td>00</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Ohm_32_320_00</td>\n",
       "      <td>data/AIBO/wav/Ohm_32_320_00.wav</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18215</th>\n",
       "      <td>Ohm</td>\n",
       "      <td>32.0</td>\n",
       "      <td>321</td>\n",
       "      <td>00</td>\n",
       "      <td>P</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Ohm_32_321_00</td>\n",
       "      <td>data/AIBO/wav/Ohm_32_321_00.wav</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18216</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18217 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source  speaker n_rec   num label percentage        filename  \\\n",
       "0       Mont      1.0   000    00     N          1  Mont_01_000_00   \n",
       "1       Mont      1.0   001    00     N          1  Mont_01_001_00   \n",
       "2       Mont      1.0   001    01     N          1  Mont_01_001_01   \n",
       "3       Mont      1.0   004    00     N        0.9  Mont_01_004_00   \n",
       "4       Mont      1.0   005    00     N          1  Mont_01_005_00   \n",
       "...      ...      ...   ...   ...   ...        ...             ...   \n",
       "18212    Ohm     32.0   318    00     E        0.4   Ohm_32_318_00   \n",
       "18213    Ohm     32.0   319    00     E        0.6   Ohm_32_319_00   \n",
       "18214    Ohm     32.0   320    00     N        0.9   Ohm_32_320_00   \n",
       "18215    Ohm     32.0   321    00     P        0.7   Ohm_32_321_00   \n",
       "18216             NaN  None  None  None       None             NaN   \n",
       "\n",
       "                                   path   lb  \n",
       "0      data/AIBO/wav/Mont_01_000_00.wav  2.0  \n",
       "1      data/AIBO/wav/Mont_01_001_00.wav  2.0  \n",
       "2      data/AIBO/wav/Mont_01_001_01.wav  2.0  \n",
       "3      data/AIBO/wav/Mont_01_004_00.wav  2.0  \n",
       "4      data/AIBO/wav/Mont_01_005_00.wav  2.0  \n",
       "...                                 ...  ...  \n",
       "18212   data/AIBO/wav/Ohm_32_318_00.wav  1.0  \n",
       "18213   data/AIBO/wav/Ohm_32_319_00.wav  1.0  \n",
       "18214   data/AIBO/wav/Ohm_32_320_00.wav  2.0  \n",
       "18215   data/AIBO/wav/Ohm_32_321_00.wav  3.0  \n",
       "18216                               NaN  NaN  \n",
       "\n",
       "[18217 rows x 9 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "242b4c7e-c248-4e69-9d4b-2742d67117d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18217"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d0ecd3-d205-4131-8561-abcfa3fb905e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d816419b-29bb-478a-b8fa-3043baf8de14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ohm     9959\n",
       "Mont    8257\n",
       "           1\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "22e5ab47-7b2f-446c-bc17-55cc795fe166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(last=25, split_ratio=0.7, seed=13):\n",
    "    np.random.seed(seed)\n",
    "    train_size = int(last * split_ratio)\n",
    "    val_size = int((1 - split_ratio)/2 * last)\n",
    "    test_size = last - train_size - val_size\n",
    "    \n",
    "    a = np.arange(1, last+1, 1)\n",
    "    b = np.random.permutation(a)\n",
    "    chunk_size = [train_size, val_size, test_size]\n",
    "    np.cumsum(chunk_size)\n",
    "    c = np.split(b, np.cumsum(chunk_size))\n",
    "    train, val, test = c[0], c[1], c[2]\n",
    "    if len(c[3]) > 0:\n",
    "        print(\"some samples left unused while splitting\")\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "62d6d410-2363-45e9-886d-5cc282ae9ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last = int(max(dict((labels_df.speaker).value_counts()).keys()))\n",
    "last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b594ba78-6111-4149-ad89-7a8cfb3efc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8, 29, 22,  1, 24, 31, 30, 25,  7,  6, 18, 20,  3,  9, 19,  5, 15,\n",
       "        13, 23, 26, 27, 12]),\n",
       " array([ 2, 17, 28, 16]),\n",
       " array([14, 32, 21,  4, 10, 11]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices, val_indices, test_indices = split_indices(last, 0.7, 6)\n",
    "split_indices(last, 0.7, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fd062324-b18f-4ab9-98c5-151d2054cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df['split']=labels_df['speaker'].apply(lambda x: 'train' if x in train_indices else ('test' if x in test_indices else 'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "56ef3346-a42a-4ff4-b30b-3cdce684b972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    12284\n",
       "test      3671\n",
       "val       2262\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8eee6ad7-62b6-4387-bcff-d0fd5213b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = labels_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "75e47500-f38a-4f18-9a60-65e7e456cfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18216"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "61eb1014-b3ce-498f-8e70-01163d932d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    10967\n",
       "E     3601\n",
       "A     1492\n",
       "R     1267\n",
       "P      889\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d8b24407-5c86-410a-8cd8-e04b105cc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.to_csv(aibo_path + 'labels_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d341d-f6ea-4b69-b741-b9e6b4b21852",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extracting .npy samplewise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0809dc84-b3c1-4d25-9166-76e4eae7da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(aibo_path + 'labels_df.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb61b68-44e6-4e65-91f4-f81d34c5ffbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18216"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99571354-3583-4766-8620-8e4f44892034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>speaker</th>\n",
       "      <th>n_rec</th>\n",
       "      <th>num</th>\n",
       "      <th>label</th>\n",
       "      <th>percentage</th>\n",
       "      <th>filename</th>\n",
       "      <th>path</th>\n",
       "      <th>lb</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mont</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mont_01_000_00</td>\n",
       "      <td>data/AIBO/wav/Mont_01_000_00.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mont</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mont_01_001_00</td>\n",
       "      <td>data/AIBO/wav/Mont_01_001_00.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mont</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mont_01_001_01</td>\n",
       "      <td>data/AIBO/wav/Mont_01_001_01.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mont</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Mont_01_004_00</td>\n",
       "      <td>data/AIBO/wav/Mont_01_004_00.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mont</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mont_01_005_00</td>\n",
       "      <td>data/AIBO/wav/Mont_01_005_00.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18211</th>\n",
       "      <td>Ohm</td>\n",
       "      <td>32.0</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Ohm_32_317_01</td>\n",
       "      <td>data/AIBO/wav/Ohm_32_317_01.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18212</th>\n",
       "      <td>Ohm</td>\n",
       "      <td>32.0</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Ohm_32_318_00</td>\n",
       "      <td>data/AIBO/wav/Ohm_32_318_00.wav</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18213</th>\n",
       "      <td>Ohm</td>\n",
       "      <td>32.0</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Ohm_32_319_00</td>\n",
       "      <td>data/AIBO/wav/Ohm_32_319_00.wav</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18214</th>\n",
       "      <td>Ohm</td>\n",
       "      <td>32.0</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Ohm_32_320_00</td>\n",
       "      <td>data/AIBO/wav/Ohm_32_320_00.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18215</th>\n",
       "      <td>Ohm</td>\n",
       "      <td>32.0</td>\n",
       "      <td>321</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Ohm_32_321_00</td>\n",
       "      <td>data/AIBO/wav/Ohm_32_321_00.wav</td>\n",
       "      <td>3.0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18216 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source  speaker  n_rec  num label  percentage        filename  \\\n",
       "0       Mont      1.0      0    0     N         1.0  Mont_01_000_00   \n",
       "1       Mont      1.0      1    0     N         1.0  Mont_01_001_00   \n",
       "2       Mont      1.0      1    1     N         1.0  Mont_01_001_01   \n",
       "3       Mont      1.0      4    0     N         0.9  Mont_01_004_00   \n",
       "4       Mont      1.0      5    0     N         1.0  Mont_01_005_00   \n",
       "...      ...      ...    ...  ...   ...         ...             ...   \n",
       "18211    Ohm     32.0    317    1     N         0.8   Ohm_32_317_01   \n",
       "18212    Ohm     32.0    318    0     E         0.4   Ohm_32_318_00   \n",
       "18213    Ohm     32.0    319    0     E         0.6   Ohm_32_319_00   \n",
       "18214    Ohm     32.0    320    0     N         0.9   Ohm_32_320_00   \n",
       "18215    Ohm     32.0    321    0     P         0.7   Ohm_32_321_00   \n",
       "\n",
       "                                   path   lb  split  \n",
       "0      data/AIBO/wav/Mont_01_000_00.wav  2.0  train  \n",
       "1      data/AIBO/wav/Mont_01_001_00.wav  2.0  train  \n",
       "2      data/AIBO/wav/Mont_01_001_01.wav  2.0  train  \n",
       "3      data/AIBO/wav/Mont_01_004_00.wav  2.0  train  \n",
       "4      data/AIBO/wav/Mont_01_005_00.wav  2.0  train  \n",
       "...                                 ...  ...    ...  \n",
       "18211   data/AIBO/wav/Ohm_32_317_01.wav  2.0   test  \n",
       "18212   data/AIBO/wav/Ohm_32_318_00.wav  1.0   test  \n",
       "18213   data/AIBO/wav/Ohm_32_319_00.wav  1.0   test  \n",
       "18214   data/AIBO/wav/Ohm_32_320_00.wav  2.0   test  \n",
       "18215   data/AIBO/wav/Ohm_32_321_00.wav  3.0   test  \n",
       "\n",
       "[18216 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17851eee-8479-49e1-ac30-23786f42d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_path(file, split):    \n",
    "    return save_path + model_mode + \"_extract_features/\" + split + '-' + file + '.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b205f266-666f-4579-8131-aa230a87cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_files = []\n",
    "problems = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "218669a9-9068-4582-b35e-34399ff43aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k,v in labels_df.iterrows():\n",
    "    try:\n",
    "        if not isfile(v['path']):\n",
    "            na_files.append(v['path'])\n",
    "            print(\"wav for {} not available\". format(v['filename']))\n",
    "        elif isfile(w2v_path(v['filename'], v['split'])):\n",
    "            pass\n",
    "            #print(\"w2v features found for {}\".format(v['filename']))\n",
    "        else:\n",
    "            #ft, hs = Wav2Vec_Model(v['path'])\n",
    "            ft, hs = Wav2Vec_Models(v['path'], model_name=model_mode, cuda=True)\n",
    "            #np.save(save_path + \"extract_features/\" + v['split'] + '-' + v['filename'] + '.npy', ft)\n",
    "            np.save(save_path + model_mode + \"_extract_features/\" + v['split'] + '-' + v['filename'] + '.npy', ft)\n",
    "            np.save(save_path + model_mode + \"_hidden_states/\" + v['split'] + '-' + v['filename'] + '.npy', hs)\n",
    "            print(\"saved for {}\".format(v['filename']))\n",
    "    except:\n",
    "        problems.append(v['filename'])\n",
    "        print(\"wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfd2a253-2193-4770-9e23-2a7dbd54aaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35e82ce0-b5ed-4081-a773-369b14573449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f4ef9-1427-4529-980c-09171c06f4e7",
   "metadata": {},
   "source": [
    "## Gathering .npy arrays into train/val/test with features, hidden states and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47b7a22f-53e2-4ef2-bcbe-ec0600499999",
   "metadata": {},
   "outputs": [],
   "source": [
    "aibo_ft_train = []\n",
    "aibo_ft_val = []\n",
    "aibo_ft_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f3f6fa9-8c0b-4155-bcc6-950a9930b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aibo_hs_train = []\n",
    "aibo_hs_val = []\n",
    "aibo_hs_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b320e3f-4de7-4750-91fd-ef83a64c8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aibo_lb_train = []\n",
    "aibo_lb_val = []\n",
    "aibo_lb_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2579f282-bab9-4447-a233-4d6f4810dcc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in os.listdir(save_path + model_mode + \"_extract_features/\"):\n",
    "    if file.startswith(\"train-\"):\n",
    "        #filename = file.split(\"-\")[1]\n",
    "        ft = np.load(save_path + model_mode + \"_extract_features/\" + file) \n",
    "        #if len(ft)> 3000:\n",
    "        aibo_ft_train.append(ft)\n",
    "    elif file.startswith(\"val-\"):\n",
    "        #filename = file.split(\"-\")[1]\n",
    "        ft = np.load(save_path + model_mode + \"_extract_features/\" + file) \n",
    "        aibo_ft_val.append(ft)\n",
    "    else:\n",
    "        ft = np.load(save_path + model_mode + \"_extract_features/\" + file) \n",
    "        aibo_ft_test.append(ft)        \n",
    "np.save(save_path + model_mode + \"_aibo_ft_train.npy\", aibo_ft_train)\n",
    "np.save(save_path + model_mode + \"_aibo_ft_val.npy\", aibo_ft_val)\n",
    "np.save(save_path + model_mode + \"_aibo_ft_test.npy\", aibo_ft_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b744929b-1344-4c51-9d19-2fcf1bd4c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(save_path + model_mode + \"_hidden_states/\"):\n",
    "    if file.startswith(\"train-\"):\n",
    "        #filename = file.split(\"-\")[1]\n",
    "        hs = np.load(save_path + model_mode + \"_hidden_states/\" + file) \n",
    "        aibo_hs_train.append(hs)\n",
    "    elif file.startswith(\"val-\"):\n",
    "        #filename = file.split(\"-\")[1]\n",
    "        hs = np.load(save_path + model_mode + \"_hidden_states/\" + file) \n",
    "        aibo_hs_val.append(hs)\n",
    "    else:\n",
    "        hs = np.load(save_path + model_mode + \"_hidden_states/\" + file) \n",
    "        aibo_hs_test.append(hs)        \n",
    "np.save(save_path + model_mode + \"_aibo_hs_train.npy\", aibo_hs_train)\n",
    "np.save(save_path + model_mode + \"_aibo_hs_val.npy\", aibo_hs_val)\n",
    "np.save(save_path + model_mode + \"_aibo_hs_test.npy\", aibo_hs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71c1ad82-7e4c-41b9-a25e-a8f3d8cc3878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source         object\n",
       "speaker       float64\n",
       "n_rec           int64\n",
       "num             int64\n",
       "label          object\n",
       "percentage    float64\n",
       "filename       object\n",
       "path           object\n",
       "lb            float64\n",
       "split          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61727f68-7748-461c-b1b9-d9cf811b0d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in os.listdir(save_path + model_mode + \"_extract_features/\"):\n",
    "    label = labels_df.loc[labels_df['filename'] == file.split(\"-\")[1].split(\".\")[0], 'lb']\n",
    "    #print(type(label))\n",
    "    #print(type(int(float(label.values))))\n",
    "    #print(type(str(label)))\n",
    "    #lb = int(float(label.replace('\\n', ' ').split(' ')[4]))\n",
    "    lb = str(label)\n",
    "    #lb = pd.to_string(label, index=False)\n",
    "    #lb = label\n",
    "    lb = int(float(lb.replace('\\n', ' ').split(' ')[4]))\n",
    "    if file.startswith(\"train-\"):\n",
    "        aibo_lb_train.append(lb)\n",
    "    elif file.startswith(\"val-\"):\n",
    "        aibo_lb_val.append(lb)\n",
    "    else:\n",
    "        aibo_lb_test.append(lb)\n",
    "np.save(save_path + model_mode + \"_aibo_lb_train.npy\", aibo_lb_train)\n",
    "np.save(save_path + model_mode + \"_aibo_lb_val.npy\", aibo_lb_val)\n",
    "np.save(save_path + model_mode + \"_aibo_lb_test.npy\", aibo_lb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21f41768-bc61-4b3e-a004-99eb4a3b052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(os.listdir(save_path + model_mode + \"_extract_features/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac44b9c1-c017-4a00-a90d-9095d1677b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2261"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aibo_lb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e159bf37-c53e-490c-bdcc-766bb5138084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12284"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aibo_lb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ec28e8a-8ab2-4bf3-a45e-00399d6879f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2261"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aibo_lb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af44c17-1c4a-41bd-9553-66cdca5b082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(aibo_lb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d3e8c-97d7-4677-919d-a6423aceb77d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#len(aibo_hs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06dc079-f161-471a-bc82-b2947f4930e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#aibo_lb_train[634]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b068756f-9d9b-4ba2-847f-53c28335b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(aibo_lb_test[0].replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b11cc2b7-92ea-4238-930b-b85cd8c6fdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(aibo_lb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "644d8d9e-a800-480f-88ef-d55c1f36d0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#str(aibo_lb_val[0]).replace('\\n', ' ').split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "52ce0fac-079c-41b5-8547-d2c31137d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(aibo_lb_val)):\n",
    " #   a = str(aibo_lb_val[i]).replace('\\n', ' ').split(' ')[4]\n",
    "  #  aibo_lb_val[i] = int(float(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3f182875-4e1e-46c1-a6f6-1f6fdfb9a121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(int(float(aibo_lb_test[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f72f791-b45a-4679-b47d-4b07bfe8a688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(aibo_lb_train[2].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f1a7b88-2b1e-42a4-a8a4-10e89b4baabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#int(float(aibo_lb_train[2].replace('\\n', ' ').split(' ')[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b151ffb-ddf4-4a06-8bb7-b6bb063a643b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(int(float(aibo_lb_train[2].replace('\\n', ' ').split(' ')[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1823d734-0e1a-42b3-96bc-35dd1d84dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c31ae57-457b-437e-863b-6a90683d46b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3547"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(os.listdir('data/AIBO/wav/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0712d258-b3fc-44d6-89a8-2c10d67d7494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14874"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(na_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d42c0c-2c68-4a52-8178-9583e95b038a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env:Python",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
