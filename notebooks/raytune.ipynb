{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed61d34-2df1-4cc2-9f43-bb2d80a74cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, TensorDataset   # DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aac2a65-b778-43ae-86fa-4433d706caf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user\n"
     ]
    }
   ],
   "source": [
    "#local_dir = \"~/ray_results/local_dir\"\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "#assert cwd.startswith(os.path.expanduser(local_dir)), cwd\n",
    "#assert not cwd.startswith(\"~\"), cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c848b124-17f9-4849-9a6b-49d2ea517fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = cwd + \"/data/IEMOCAP/wav2vec/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ff80dc-6715-4c43-91d1-9c43333d01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca8618a-782a-46b7-9166-dc69fa659f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_option = 'xvec'\n",
    "#model_option = 'base'\n",
    "model_option = 'xlsr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "641eb1e8-a675-43f5-9755-8bc81a099ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=PATH):\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "    return trainset, testset\n",
    "    \"\"\"\n",
    "    x_train = np.load(PATH + model_option + \"_icp_hs_train.npy\")\n",
    "    x_val = np.load(PATH + model_option + \"_icp_hs_val.npy\")\n",
    "    x_test = np.load(PATH + model_option + \"_icp_hs_test.npy\")\n",
    "\n",
    "    y_train = np.load(PATH + model_option + \"_icp_lb_train.npy\", allow_pickle=True)\n",
    "    y_val = np.load(PATH + model_option + \"_icp_lb_val.npy\", allow_pickle=True)\n",
    "    y_test = np.load(PATH + model_option + \"_icp_lb_test.npy\", allow_pickle=True)\n",
    "    \"\"\"\n",
    "    x_train = np.load(PATH + \"icp_ft_train.npy\")\n",
    "    x_val = np.load(PATH + \"icp_ft_val.npy\")\n",
    "    x_test = np.load(PATH + \"icp_ft_test.npy\")\n",
    "\n",
    "    y_train = np.load(PATH + \"icp_lb_train.npy\", allow_pickle=True)\n",
    "    y_val = np.load(PATH + \"icp_lb_val.npy\", allow_pickle=True)\n",
    "    y_test = np.load(PATH + \"icp_lb_test.npy\", allow_pickle=True)\n",
    "    \"\"\"\n",
    "    print(y_train.shape, y_val.shape, y_test.shape)       # (4696,) (935,) (1407,)\n",
    "    print(x_train.shape, x_val.shape, x_test.shape)       # (4696, 3072) (935, 3072) (1407, 3072)\n",
    "\n",
    "    train_dataset = TensorDataset(torch.tensor(x_train), torch.tensor(y_train))\n",
    "    # train_dataset = TensorDataset(torch.from_numpy(x_train_eval).float(), torch.from_numpy(y_train_eval).float())\n",
    "    val_dataset = TensorDataset(torch.tensor(x_val), torch.tensor(y_val))\n",
    "    test_dataset = TensorDataset(torch.tensor(x_test), torch.tensor(y_test))\n",
    "\n",
    "    #train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True) # num_workers\n",
    "    #val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    #test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e76fe2ec-f881-4460-8648-1e857a9a763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, l1=120, l2=84):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\"\"\"\n",
    "# my simple MLP    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=7, l1=1200, l2=840):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            #nn.Linear(3072, 1000),     # icp_ft.npy\n",
    "            nn.Linear(6144, l1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(l1, l2),\n",
    "            nn.Linear(l2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convert tensor (128, 1, 28, 28) --> (128, 1*28*28)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2382c405-3696-43cd-839e-09b9a604c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, checkpoint_dir=None):\n",
    "    net = Net(num_classes, config[\"l1\"], config[\"l2\"])\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "    optimizer = Adam(net.parameters(), lr=config[\"lr\"], weight_decay=config[\"w_decay\"])\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    train_subset, val_subset, testset = load_data()\n",
    "\n",
    "    #test_abs = int(len(trainset) * 0.8)\n",
    "    #train_subset, val_subset = random_split(\n",
    "     #   trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=4)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=4)\n",
    "\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb17769-9c71-42ad-a0d5-1546f01c8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    train_subset, val_subset, testset = load_data()\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611338d7-5f26-4954-b9dc-34df03ee1e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 16:56:58,369\tWARNING services.py:1856 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 4294967296 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.78gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-02 16:57:00 (running for 00:00:00.16)\n",
      "Memory usage on this node: 1.5/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+\n",
      "| Trial name        | status   | loc                |   batch_size |   l1 |   l2 |          lr |\n",
      "|-------------------+----------+--------------------+--------------+------+------+-------------|\n",
      "| train_c6a31_00000 | RUNNING  | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  |\n",
      "| train_c6a31_00001 | PENDING  |                    |           32 |  160 | 1280 | 0.000370203 |\n",
      "| train_c6a31_00002 | PENDING  |                    |            2 | 2560 |  160 | 0.000672656 |\n",
      "| train_c6a31_00003 | PENDING  |                    |           64 |  320 | 1280 | 0.0123423   |\n",
      "| train_c6a31_00004 | PENDING  |                    |           32 | 2560 |   80 | 0.0069568   |\n",
      "| train_c6a31_00005 | PENDING  |                    |           16 | 2560 |  160 | 0.000452738 |\n",
      "| train_c6a31_00006 | PENDING  |                    |           64 |  640 | 1280 | 0.062483    |\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:57:05 (running for 00:00:05.20)\n",
      "Memory usage on this node: 3.7/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+\n",
      "| Trial name        | status   | loc                |   batch_size |   l1 |   l2 |          lr |\n",
      "|-------------------+----------+--------------------+--------------+------+------+-------------|\n",
      "| train_c6a31_00000 | RUNNING  | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  |\n",
      "| train_c6a31_00001 | PENDING  |                    |           32 |  160 | 1280 | 0.000370203 |\n",
      "| train_c6a31_00002 | PENDING  |                    |            2 | 2560 |  160 | 0.000672656 |\n",
      "| train_c6a31_00003 | PENDING  |                    |           64 |  320 | 1280 | 0.0123423   |\n",
      "| train_c6a31_00004 | PENDING  |                    |           32 | 2560 |   80 | 0.0069568   |\n",
      "| train_c6a31_00005 | PENDING  |                    |           16 | 2560 |  160 | 0.000452738 |\n",
      "| train_c6a31_00006 | PENDING  |                    |           64 |  640 | 1280 | 0.062483    |\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train pid=2569)\u001b[0m (4520,) (1348,) (1512,)\n",
      "\u001b[2m\u001b[36m(train pid=2569)\u001b[0m (4520, 6144) (1348, 6144) (1512, 6144)\n",
      "\u001b[2m\u001b[36m(train pid=2569)\u001b[0m [1,  2000] loss: nan\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:57:10 (running for 00:00:10.23)\n",
      "Memory usage on this node: 4.2/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+\n",
      "| Trial name        | status   | loc                |   batch_size |   l1 |   l2 |          lr |\n",
      "|-------------------+----------+--------------------+--------------+------+------+-------------|\n",
      "| train_c6a31_00000 | RUNNING  | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  |\n",
      "| train_c6a31_00001 | PENDING  |                    |           32 |  160 | 1280 | 0.000370203 |\n",
      "| train_c6a31_00002 | PENDING  |                    |            2 | 2560 |  160 | 0.000672656 |\n",
      "| train_c6a31_00003 | PENDING  |                    |           64 |  320 | 1280 | 0.0123423   |\n",
      "| train_c6a31_00004 | PENDING  |                    |           32 | 2560 |   80 | 0.0069568   |\n",
      "| train_c6a31_00005 | PENDING  |                    |           16 | 2560 |  160 | 0.000452738 |\n",
      "| train_c6a31_00006 | PENDING  |                    |           64 |  640 | 1280 | 0.062483    |\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+\n",
      "\n",
      "\n",
      "Result for train_c6a31_00000:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-57-11\n",
      "  done: false\n",
      "  experiment_id: 33b8024a4bfa4ed9b1e4c7de0e5c6d8b\n",
      "  hostname: default\n",
      "  iterations_since_restore: 1\n",
      "  loss: .nan\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2569\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 9.996040344238281\n",
      "  time_this_iter_s: 9.996040344238281\n",
      "  time_total_s: 9.996040344238281\n",
      "  timestamp: 1646240231\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c6a31_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(train pid=2569)\u001b[0m [2,  2000] loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/env/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1374: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-03-02 16:57:16 (running for 00:00:16.23)\n",
      "Memory usage on this node: 4.2/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: nan\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "| Trial name        | status   | loc                |   batch_size |   l1 |   l2 |          lr |   loss |   accuracy |   training_iteration |\n",
      "|-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------|\n",
      "| train_c6a31_00000 | RUNNING  | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  |    nan |   0.268546 |                    1 |\n",
      "| train_c6a31_00001 | PENDING  |                    |           32 |  160 | 1280 | 0.000370203 |        |            |                      |\n",
      "| train_c6a31_00002 | PENDING  |                    |            2 | 2560 |  160 | 0.000672656 |        |            |                      |\n",
      "| train_c6a31_00003 | PENDING  |                    |           64 |  320 | 1280 | 0.0123423   |        |            |                      |\n",
      "| train_c6a31_00004 | PENDING  |                    |           32 | 2560 |   80 | 0.0069568   |        |            |                      |\n",
      "| train_c6a31_00005 | PENDING  |                    |           16 | 2560 |  160 | 0.000452738 |        |            |                      |\n",
      "| train_c6a31_00006 | PENDING  |                    |           64 |  640 | 1280 | 0.062483    |        |            |                      |\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_c6a31_00000:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-57-16\n",
      "  done: false\n",
      "  experiment_id: 33b8024a4bfa4ed9b1e4c7de0e5c6d8b\n",
      "  hostname: default\n",
      "  iterations_since_restore: 2\n",
      "  loss: .nan\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2569\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 15.321076393127441\n",
      "  time_this_iter_s: 5.32503604888916\n",
      "  time_total_s: 15.321076393127441\n",
      "  timestamp: 1646240236\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: c6a31_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(train pid=2569)\u001b[0m [3,  2000] loss: nan\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:57:21 (running for 00:00:21.56)\n",
      "Memory usage on this node: 4.2/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: nan | Iter 1.000: nan\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "| Trial name        | status   | loc                |   batch_size |   l1 |   l2 |          lr |   loss |   accuracy |   training_iteration |\n",
      "|-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------|\n",
      "| train_c6a31_00000 | RUNNING  | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  |    nan |   0.268546 |                    2 |\n",
      "| train_c6a31_00001 | PENDING  |                    |           32 |  160 | 1280 | 0.000370203 |        |            |                      |\n",
      "| train_c6a31_00002 | PENDING  |                    |            2 | 2560 |  160 | 0.000672656 |        |            |                      |\n",
      "| train_c6a31_00003 | PENDING  |                    |           64 |  320 | 1280 | 0.0123423   |        |            |                      |\n",
      "| train_c6a31_00004 | PENDING  |                    |           32 | 2560 |   80 | 0.0069568   |        |            |                      |\n",
      "| train_c6a31_00005 | PENDING  |                    |           16 | 2560 |  160 | 0.000452738 |        |            |                      |\n",
      "| train_c6a31_00006 | PENDING  |                    |           64 |  640 | 1280 | 0.062483    |        |            |                      |\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_c6a31_00000:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-57-21\n",
      "  done: false\n",
      "  experiment_id: 33b8024a4bfa4ed9b1e4c7de0e5c6d8b\n",
      "  hostname: default\n",
      "  iterations_since_restore: 3\n",
      "  loss: .nan\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2569\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 20.63513970375061\n",
      "  time_this_iter_s: 5.314063310623169\n",
      "  time_total_s: 20.63513970375061\n",
      "  timestamp: 1646240241\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: c6a31_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(train pid=2569)\u001b[0m [4,  2000] loss: nan\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:57:26 (running for 00:00:26.86)\n",
      "Memory usage on this node: 4.2/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: nan | Iter 1.000: nan\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "| Trial name        | status   | loc                |   batch_size |   l1 |   l2 |          lr |   loss |   accuracy |   training_iteration |\n",
      "|-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------|\n",
      "| train_c6a31_00000 | RUNNING  | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  |    nan |   0.268546 |                    3 |\n",
      "| train_c6a31_00001 | PENDING  |                    |           32 |  160 | 1280 | 0.000370203 |        |            |                      |\n",
      "| train_c6a31_00002 | PENDING  |                    |            2 | 2560 |  160 | 0.000672656 |        |            |                      |\n",
      "| train_c6a31_00003 | PENDING  |                    |           64 |  320 | 1280 | 0.0123423   |        |            |                      |\n",
      "| train_c6a31_00004 | PENDING  |                    |           32 | 2560 |   80 | 0.0069568   |        |            |                      |\n",
      "| train_c6a31_00005 | PENDING  |                    |           16 | 2560 |  160 | 0.000452738 |        |            |                      |\n",
      "| train_c6a31_00006 | PENDING  |                    |           64 |  640 | 1280 | 0.062483    |        |            |                      |\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_c6a31_00000:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-57-27\n",
      "  done: false\n",
      "  experiment_id: 33b8024a4bfa4ed9b1e4c7de0e5c6d8b\n",
      "  hostname: default\n",
      "  iterations_since_restore: 4\n",
      "  loss: .nan\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2569\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 25.94751739501953\n",
      "  time_this_iter_s: 5.312377691268921\n",
      "  time_total_s: 25.94751739501953\n",
      "  timestamp: 1646240247\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: c6a31_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(train pid=2569)\u001b[0m [5,  2000] loss: nan\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:57:32 (running for 00:00:32.19)\n",
      "Memory usage on this node: 4.3/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: nan | Iter 2.000: nan | Iter 1.000: nan\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "| Trial name        | status   | loc                |   batch_size |   l1 |   l2 |          lr |   loss |   accuracy |   training_iteration |\n",
      "|-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------|\n",
      "| train_c6a31_00000 | RUNNING  | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  |    nan |   0.268546 |                    4 |\n",
      "| train_c6a31_00001 | PENDING  |                    |           32 |  160 | 1280 | 0.000370203 |        |            |                      |\n",
      "| train_c6a31_00002 | PENDING  |                    |            2 | 2560 |  160 | 0.000672656 |        |            |                      |\n",
      "| train_c6a31_00003 | PENDING  |                    |           64 |  320 | 1280 | 0.0123423   |        |            |                      |\n",
      "| train_c6a31_00004 | PENDING  |                    |           32 | 2560 |   80 | 0.0069568   |        |            |                      |\n",
      "| train_c6a31_00005 | PENDING  |                    |           16 | 2560 |  160 | 0.000452738 |        |            |                      |\n",
      "| train_c6a31_00006 | PENDING  |                    |           64 |  640 | 1280 | 0.062483    |        |            |                      |\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_c6a31_00000:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-57-32\n",
      "  done: false\n",
      "  experiment_id: 33b8024a4bfa4ed9b1e4c7de0e5c6d8b\n",
      "  hostname: default\n",
      "  iterations_since_restore: 5\n",
      "  loss: .nan\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2569\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 31.40595841407776\n",
      "  time_this_iter_s: 5.4584410190582275\n",
      "  time_total_s: 31.40595841407776\n",
      "  timestamp: 1646240252\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: c6a31_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(train pid=2569)\u001b[0m [6,  2000] loss: nan\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:57:37 (running for 00:00:37.64)\n",
      "Memory usage on this node: 4.3/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: nan | Iter 2.000: nan | Iter 1.000: nan\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "| Trial name        | status   | loc                |   batch_size |   l1 |   l2 |          lr |   loss |   accuracy |   training_iteration |\n",
      "|-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------|\n",
      "| train_c6a31_00000 | RUNNING  | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  |    nan |   0.268546 |                    5 |\n",
      "| train_c6a31_00001 | PENDING  |                    |           32 |  160 | 1280 | 0.000370203 |        |            |                      |\n",
      "| train_c6a31_00002 | PENDING  |                    |            2 | 2560 |  160 | 0.000672656 |        |            |                      |\n",
      "| train_c6a31_00003 | PENDING  |                    |           64 |  320 | 1280 | 0.0123423   |        |            |                      |\n",
      "| train_c6a31_00004 | PENDING  |                    |           32 | 2560 |   80 | 0.0069568   |        |            |                      |\n",
      "| train_c6a31_00005 | PENDING  |                    |           16 | 2560 |  160 | 0.000452738 |        |            |                      |\n",
      "| train_c6a31_00006 | PENDING  |                    |           64 |  640 | 1280 | 0.062483    |        |            |                      |\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_c6a31_00000:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-57-37\n",
      "  done: false\n",
      "  experiment_id: 33b8024a4bfa4ed9b1e4c7de0e5c6d8b\n",
      "  hostname: default\n",
      "  iterations_since_restore: 6\n",
      "  loss: .nan\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2569\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 36.798686265945435\n",
      "  time_this_iter_s: 5.392727851867676\n",
      "  time_total_s: 36.798686265945435\n",
      "  timestamp: 1646240257\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: c6a31_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(train pid=2569)\u001b[0m [7,  2000] loss: nan\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:57:42 (running for 00:00:43.04)\n",
      "Memory usage on this node: 4.3/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: nan | Iter 2.000: nan | Iter 1.000: nan\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "| Trial name        | status   | loc                |   batch_size |   l1 |   l2 |          lr |   loss |   accuracy |   training_iteration |\n",
      "|-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------|\n",
      "| train_c6a31_00000 | RUNNING  | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  |    nan |   0.268546 |                    6 |\n",
      "| train_c6a31_00001 | PENDING  |                    |           32 |  160 | 1280 | 0.000370203 |        |            |                      |\n",
      "| train_c6a31_00002 | PENDING  |                    |            2 | 2560 |  160 | 0.000672656 |        |            |                      |\n",
      "| train_c6a31_00003 | PENDING  |                    |           64 |  320 | 1280 | 0.0123423   |        |            |                      |\n",
      "| train_c6a31_00004 | PENDING  |                    |           32 | 2560 |   80 | 0.0069568   |        |            |                      |\n",
      "| train_c6a31_00005 | PENDING  |                    |           16 | 2560 |  160 | 0.000452738 |        |            |                      |\n",
      "| train_c6a31_00006 | PENDING  |                    |           64 |  640 | 1280 | 0.062483    |        |            |                      |\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_c6a31_00000:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-57-43\n",
      "  done: false\n",
      "  experiment_id: 33b8024a4bfa4ed9b1e4c7de0e5c6d8b\n",
      "  hostname: default\n",
      "  iterations_since_restore: 7\n",
      "  loss: .nan\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2569\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 42.066447257995605\n",
      "  time_this_iter_s: 5.267760992050171\n",
      "  time_total_s: 42.066447257995605\n",
      "  timestamp: 1646240263\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: c6a31_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(train pid=2569)\u001b[0m [8,  2000] loss: nan\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:57:48 (running for 00:00:48.30)\n",
      "Memory usage on this node: 4.3/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: nan | Iter 2.000: nan | Iter 1.000: nan\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "| Trial name        | status   | loc                |   batch_size |   l1 |   l2 |          lr |   loss |   accuracy |   training_iteration |\n",
      "|-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------|\n",
      "| train_c6a31_00000 | RUNNING  | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  |    nan |   0.268546 |                    7 |\n",
      "| train_c6a31_00001 | PENDING  |                    |           32 |  160 | 1280 | 0.000370203 |        |            |                      |\n",
      "| train_c6a31_00002 | PENDING  |                    |            2 | 2560 |  160 | 0.000672656 |        |            |                      |\n",
      "| train_c6a31_00003 | PENDING  |                    |           64 |  320 | 1280 | 0.0123423   |        |            |                      |\n",
      "| train_c6a31_00004 | PENDING  |                    |           32 | 2560 |   80 | 0.0069568   |        |            |                      |\n",
      "| train_c6a31_00005 | PENDING  |                    |           16 | 2560 |  160 | 0.000452738 |        |            |                      |\n",
      "| train_c6a31_00006 | PENDING  |                    |           64 |  640 | 1280 | 0.062483    |        |            |                      |\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_c6a31_00000:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-57-48\n",
      "  done: false\n",
      "  experiment_id: 33b8024a4bfa4ed9b1e4c7de0e5c6d8b\n",
      "  hostname: default\n",
      "  iterations_since_restore: 8\n",
      "  loss: .nan\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2569\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 47.369077920913696\n",
      "  time_this_iter_s: 5.302630662918091\n",
      "  time_total_s: 47.369077920913696\n",
      "  timestamp: 1646240268\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: c6a31_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(train pid=2569)\u001b[0m [9,  2000] loss: nan\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:57:53 (running for 00:00:53.61)\n",
      "Memory usage on this node: 4.3/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: nan | Iter 4.000: nan | Iter 2.000: nan | Iter 1.000: nan\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "| Trial name        | status   | loc                |   batch_size |   l1 |   l2 |          lr |   loss |   accuracy |   training_iteration |\n",
      "|-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------|\n",
      "| train_c6a31_00000 | RUNNING  | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  |    nan |   0.268546 |                    8 |\n",
      "| train_c6a31_00001 | PENDING  |                    |           32 |  160 | 1280 | 0.000370203 |        |            |                      |\n",
      "| train_c6a31_00002 | PENDING  |                    |            2 | 2560 |  160 | 0.000672656 |        |            |                      |\n",
      "| train_c6a31_00003 | PENDING  |                    |           64 |  320 | 1280 | 0.0123423   |        |            |                      |\n",
      "| train_c6a31_00004 | PENDING  |                    |           32 | 2560 |   80 | 0.0069568   |        |            |                      |\n",
      "| train_c6a31_00005 | PENDING  |                    |           16 | 2560 |  160 | 0.000452738 |        |            |                      |\n",
      "| train_c6a31_00006 | PENDING  |                    |           64 |  640 | 1280 | 0.062483    |        |            |                      |\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_c6a31_00000:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-57-53\n",
      "  done: false\n",
      "  experiment_id: 33b8024a4bfa4ed9b1e4c7de0e5c6d8b\n",
      "  hostname: default\n",
      "  iterations_since_restore: 9\n",
      "  loss: .nan\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2569\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 52.65194869041443\n",
      "  time_this_iter_s: 5.282870769500732\n",
      "  time_total_s: 52.65194869041443\n",
      "  timestamp: 1646240273\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: c6a31_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(train pid=2569)\u001b[0m [10,  2000] loss: nan\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:57:58 (running for 00:00:58.88)\n",
      "Memory usage on this node: 4.3/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: nan | Iter 4.000: nan | Iter 2.000: nan | Iter 1.000: nan\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "| Trial name        | status   | loc                |   batch_size |   l1 |   l2 |          lr |   loss |   accuracy |   training_iteration |\n",
      "|-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------|\n",
      "| train_c6a31_00000 | RUNNING  | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  |    nan |   0.268546 |                    9 |\n",
      "| train_c6a31_00001 | PENDING  |                    |           32 |  160 | 1280 | 0.000370203 |        |            |                      |\n",
      "| train_c6a31_00002 | PENDING  |                    |            2 | 2560 |  160 | 0.000672656 |        |            |                      |\n",
      "| train_c6a31_00003 | PENDING  |                    |           64 |  320 | 1280 | 0.0123423   |        |            |                      |\n",
      "| train_c6a31_00004 | PENDING  |                    |           32 | 2560 |   80 | 0.0069568   |        |            |                      |\n",
      "| train_c6a31_00005 | PENDING  |                    |           16 | 2560 |  160 | 0.000452738 |        |            |                      |\n",
      "| train_c6a31_00006 | PENDING  |                    |           64 |  640 | 1280 | 0.062483    |        |            |                      |\n",
      "+-------------------+----------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_c6a31_00000:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-57-59\n",
      "  done: false\n",
      "  experiment_id: 33b8024a4bfa4ed9b1e4c7de0e5c6d8b\n",
      "  hostname: default\n",
      "  iterations_since_restore: 10\n",
      "  loss: .nan\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2569\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 58.0071804523468\n",
      "  time_this_iter_s: 5.355231761932373\n",
      "  time_total_s: 58.0071804523468\n",
      "  timestamp: 1646240279\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: c6a31_00000\n",
      "  \n",
      "Result for train_c6a31_00000:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-57-59\n",
      "  done: true\n",
      "  experiment_id: 33b8024a4bfa4ed9b1e4c7de0e5c6d8b\n",
      "  experiment_tag: 0_batch_size=2,l1=40,l2=320,lr=0.0084023\n",
      "  hostname: default\n",
      "  iterations_since_restore: 10\n",
      "  loss: .nan\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2569\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 58.0071804523468\n",
      "  time_this_iter_s: 5.355231761932373\n",
      "  time_total_s: 58.0071804523468\n",
      "  timestamp: 1646240279\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: c6a31_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(train pid=2569)\u001b[0m Finished Training\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:58:04 (running for 00:01:04.55)\n",
      "Memory usage on this node: 2.5/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: nan | Iter 4.000: nan | Iter 2.000: nan | Iter 1.000: nan\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (5 PENDING, 1 RUNNING, 1 TERMINATED)\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "| Trial name        | status     | loc                |   batch_size |   l1 |   l2 |          lr |   loss |   accuracy |   training_iteration |\n",
      "|-------------------+------------+--------------------+--------------+------+------+-------------+--------+------------+----------------------|\n",
      "| train_c6a31_00001 | RUNNING    | 169.254.255.2:2568 |           32 |  160 | 1280 | 0.000370203 |        |            |                      |\n",
      "| train_c6a31_00002 | PENDING    |                    |            2 | 2560 |  160 | 0.000672656 |        |            |                      |\n",
      "| train_c6a31_00003 | PENDING    |                    |           64 |  320 | 1280 | 0.0123423   |        |            |                      |\n",
      "| train_c6a31_00004 | PENDING    |                    |           32 | 2560 |   80 | 0.0069568   |        |            |                      |\n",
      "| train_c6a31_00005 | PENDING    |                    |           16 | 2560 |  160 | 0.000452738 |        |            |                      |\n",
      "| train_c6a31_00006 | PENDING    |                    |           64 |  640 | 1280 | 0.062483    |        |            |                      |\n",
      "| train_c6a31_00000 | TERMINATED | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  |    nan |   0.268546 |                   10 |\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+--------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train pid=2568)\u001b[0m (4520,) (1348,) (1512,)\n",
      "\u001b[2m\u001b[36m(train pid=2568)\u001b[0m (4520, 6144) (1348, 6144) (1512, 6144)\n",
      "Result for train_c6a31_00001:\n",
      "  accuracy: 0.24183976261127596\n",
      "  date: 2022-03-02_16-58-07\n",
      "  done: false\n",
      "  experiment_id: cc81450e2b004e5e9dbc7d2756cdcaf6\n",
      "  hostname: default\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.8456376347430916\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2568\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 5.385363817214966\n",
      "  time_this_iter_s: 5.385363817214966\n",
      "  time_total_s: 5.385363817214966\n",
      "  timestamp: 1646240287\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c6a31_00001\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:58:10 (running for 00:01:10.22)\n",
      "Memory usage on this node: 4.2/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: nan | Iter 4.000: -1.6864815035531686 | Iter 2.000: -1.7703009400256844 | Iter 1.000: -1.8456376347430916\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (5 PENDING, 1 RUNNING, 1 TERMINATED)\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "| Trial name        | status     | loc                |   batch_size |   l1 |   l2 |          lr |      loss |   accuracy |   training_iteration |\n",
      "|-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------|\n",
      "| train_c6a31_00001 | RUNNING    | 169.254.255.2:2568 |           32 |  160 | 1280 | 0.000370203 |   1.68648 |   0.269288 |                    4 |\n",
      "| train_c6a31_00002 | PENDING    |                    |            2 | 2560 |  160 | 0.000672656 |           |            |                      |\n",
      "| train_c6a31_00003 | PENDING    |                    |           64 |  320 | 1280 | 0.0123423   |           |            |                      |\n",
      "| train_c6a31_00004 | PENDING    |                    |           32 | 2560 |   80 | 0.0069568   |           |            |                      |\n",
      "| train_c6a31_00005 | PENDING    |                    |           16 | 2560 |  160 | 0.000452738 |           |            |                      |\n",
      "| train_c6a31_00006 | PENDING    |                    |           64 |  640 | 1280 | 0.062483    |           |            |                      |\n",
      "| train_c6a31_00000 | TERMINATED | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  | nan       |   0.268546 |                   10 |\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_c6a31_00001:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-58-13\n",
      "  done: false\n",
      "  experiment_id: cc81450e2b004e5e9dbc7d2756cdcaf6\n",
      "  hostname: default\n",
      "  iterations_since_restore: 8\n",
      "  loss: 1.626642759456191\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2568\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 10.73162841796875\n",
      "  time_this_iter_s: 0.7469437122344971\n",
      "  time_total_s: 10.73162841796875\n",
      "  timestamp: 1646240293\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: c6a31_00001\n",
      "  \n",
      "Result for train_c6a31_00001:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-58-14\n",
      "  done: true\n",
      "  experiment_id: cc81450e2b004e5e9dbc7d2756cdcaf6\n",
      "  experiment_tag: 1_batch_size=32,l1=160,l2=1280,lr=0.0003702\n",
      "  hostname: default\n",
      "  iterations_since_restore: 10\n",
      "  loss: 1.61570939352346\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2568\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 12.249168157577515\n",
      "  time_this_iter_s: 0.7597980499267578\n",
      "  time_total_s: 12.249168157577515\n",
      "  timestamp: 1646240294\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: c6a31_00001\n",
      "  \n",
      "\u001b[2m\u001b[36m(train pid=2568)\u001b[0m Finished Training\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:58:15 (running for 00:01:15.22)\n",
      "Memory usage on this node: 1.4/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: -1.626642759456191 | Iter 4.000: -1.6864815035531686 | Iter 2.000: -1.7703009400256844 | Iter 1.000: -1.8456376347430916\n",
      "Resources requested: 0/4 CPUs, 0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (5 PENDING, 2 TERMINATED)\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "| Trial name        | status     | loc                |   batch_size |   l1 |   l2 |          lr |      loss |   accuracy |   training_iteration |\n",
      "|-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------|\n",
      "| train_c6a31_00002 | PENDING    |                    |            2 | 2560 |  160 | 0.000672656 |           |            |                      |\n",
      "| train_c6a31_00003 | PENDING    |                    |           64 |  320 | 1280 | 0.0123423   |           |            |                      |\n",
      "| train_c6a31_00004 | PENDING    |                    |           32 | 2560 |   80 | 0.0069568   |           |            |                      |\n",
      "| train_c6a31_00005 | PENDING    |                    |           16 | 2560 |  160 | 0.000452738 |           |            |                      |\n",
      "| train_c6a31_00006 | PENDING    |                    |           64 |  640 | 1280 | 0.062483    |           |            |                      |\n",
      "| train_c6a31_00000 | TERMINATED | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  | nan       |   0.268546 |                   10 |\n",
      "| train_c6a31_00001 | TERMINATED | 169.254.255.2:2568 |           32 |  160 | 1280 | 0.000370203 |   1.61571 |   0.268546 |                   10 |\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:58:20 (running for 00:01:20.55)\n",
      "Memory usage on this node: 2.4/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: -1.626642759456191 | Iter 4.000: -1.6864815035531686 | Iter 2.000: -1.7703009400256844 | Iter 1.000: -1.8456376347430916\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (4 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "| Trial name        | status     | loc                |   batch_size |   l1 |   l2 |          lr |      loss |   accuracy |   training_iteration |\n",
      "|-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------|\n",
      "| train_c6a31_00002 | RUNNING    | 169.254.255.2:2570 |            2 | 2560 |  160 | 0.000672656 |           |            |                      |\n",
      "| train_c6a31_00003 | PENDING    |                    |           64 |  320 | 1280 | 0.0123423   |           |            |                      |\n",
      "| train_c6a31_00004 | PENDING    |                    |           32 | 2560 |   80 | 0.0069568   |           |            |                      |\n",
      "| train_c6a31_00005 | PENDING    |                    |           16 | 2560 |  160 | 0.000452738 |           |            |                      |\n",
      "| train_c6a31_00006 | PENDING    |                    |           64 |  640 | 1280 | 0.062483    |           |            |                      |\n",
      "| train_c6a31_00000 | TERMINATED | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  | nan       |   0.268546 |                   10 |\n",
      "| train_c6a31_00001 | TERMINATED | 169.254.255.2:2568 |           32 |  160 | 1280 | 0.000370203 |   1.61571 |   0.268546 |                   10 |\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train pid=2570)\u001b[0m (4520,) (1348,) (1512,)\n",
      "\u001b[2m\u001b[36m(train pid=2570)\u001b[0m (4520, 6144) (1348, 6144) (1512, 6144)\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:58:25 (running for 00:01:25.57)\n",
      "Memory usage on this node: 4.2/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: -1.626642759456191 | Iter 4.000: -1.6864815035531686 | Iter 2.000: -1.7703009400256844 | Iter 1.000: -1.8456376347430916\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (4 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "| Trial name        | status     | loc                |   batch_size |   l1 |   l2 |          lr |      loss |   accuracy |   training_iteration |\n",
      "|-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------|\n",
      "| train_c6a31_00002 | RUNNING    | 169.254.255.2:2570 |            2 | 2560 |  160 | 0.000672656 |           |            |                      |\n",
      "| train_c6a31_00003 | PENDING    |                    |           64 |  320 | 1280 | 0.0123423   |           |            |                      |\n",
      "| train_c6a31_00004 | PENDING    |                    |           32 | 2560 |   80 | 0.0069568   |           |            |                      |\n",
      "| train_c6a31_00005 | PENDING    |                    |           16 | 2560 |  160 | 0.000452738 |           |            |                      |\n",
      "| train_c6a31_00006 | PENDING    |                    |           64 |  640 | 1280 | 0.062483    |           |            |                      |\n",
      "| train_c6a31_00000 | TERMINATED | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  | nan       |   0.268546 |                   10 |\n",
      "| train_c6a31_00001 | TERMINATED | 169.254.255.2:2568 |           32 |  160 | 1280 | 0.000370203 |   1.61571 |   0.268546 |                   10 |\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:58:30 (running for 00:01:30.59)\n",
      "Memory usage on this node: 4.2/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: -1.626642759456191 | Iter 4.000: -1.6864815035531686 | Iter 2.000: -1.7703009400256844 | Iter 1.000: -1.8456376347430916\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (4 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "| Trial name        | status     | loc                |   batch_size |   l1 |   l2 |          lr |      loss |   accuracy |   training_iteration |\n",
      "|-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------|\n",
      "| train_c6a31_00002 | RUNNING    | 169.254.255.2:2570 |            2 | 2560 |  160 | 0.000672656 |           |            |                      |\n",
      "| train_c6a31_00003 | PENDING    |                    |           64 |  320 | 1280 | 0.0123423   |           |            |                      |\n",
      "| train_c6a31_00004 | PENDING    |                    |           32 | 2560 |   80 | 0.0069568   |           |            |                      |\n",
      "| train_c6a31_00005 | PENDING    |                    |           16 | 2560 |  160 | 0.000452738 |           |            |                      |\n",
      "| train_c6a31_00006 | PENDING    |                    |           64 |  640 | 1280 | 0.062483    |           |            |                      |\n",
      "| train_c6a31_00000 | TERMINATED | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  | nan       |   0.268546 |                   10 |\n",
      "| train_c6a31_00001 | TERMINATED | 169.254.255.2:2568 |           32 |  160 | 1280 | 0.000370203 |   1.61571 |   0.268546 |                   10 |\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train pid=2570)\u001b[0m [1,  2000] loss: 3.823\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:58:35 (running for 00:01:35.61)\n",
      "Memory usage on this node: 4.2/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: -1.626642759456191 | Iter 4.000: -1.6864815035531686 | Iter 2.000: -1.7703009400256844 | Iter 1.000: -1.8456376347430916\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (4 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "| Trial name        | status     | loc                |   batch_size |   l1 |   l2 |          lr |      loss |   accuracy |   training_iteration |\n",
      "|-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------|\n",
      "| train_c6a31_00002 | RUNNING    | 169.254.255.2:2570 |            2 | 2560 |  160 | 0.000672656 |           |            |                      |\n",
      "| train_c6a31_00003 | PENDING    |                    |           64 |  320 | 1280 | 0.0123423   |           |            |                      |\n",
      "| train_c6a31_00004 | PENDING    |                    |           32 | 2560 |   80 | 0.0069568   |           |            |                      |\n",
      "| train_c6a31_00005 | PENDING    |                    |           16 | 2560 |  160 | 0.000452738 |           |            |                      |\n",
      "| train_c6a31_00006 | PENDING    |                    |           64 |  640 | 1280 | 0.062483    |           |            |                      |\n",
      "| train_c6a31_00000 | TERMINATED | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  | nan       |   0.268546 |                   10 |\n",
      "| train_c6a31_00001 | TERMINATED | 169.254.255.2:2568 |           32 |  160 | 1280 | 0.000370203 |   1.61571 |   0.268546 |                   10 |\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_c6a31_00002:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-58-35\n",
      "  done: false\n",
      "  experiment_id: 2061c12ba09248cf9e2c8d21070d041e\n",
      "  hostname: default\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.6016325651714993\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 17.377517700195312\n",
      "  time_this_iter_s: 17.377517700195312\n",
      "  time_total_s: 17.377517700195312\n",
      "  timestamp: 1646240315\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c6a31_00002\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:58:40 (running for 00:01:40.95)\n",
      "Memory usage on this node: 4.2/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: -1.626642759456191 | Iter 4.000: -1.6864815035531686 | Iter 2.000: -1.7703009400256844 | Iter 1.000: -1.7236350999572956\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (4 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "| Trial name        | status     | loc                |   batch_size |   l1 |   l2 |          lr |      loss |   accuracy |   training_iteration |\n",
      "|-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------|\n",
      "| train_c6a31_00002 | RUNNING    | 169.254.255.2:2570 |            2 | 2560 |  160 | 0.000672656 |   1.60163 |   0.268546 |                    1 |\n",
      "| train_c6a31_00003 | PENDING    |                    |           64 |  320 | 1280 | 0.0123423   |           |            |                      |\n",
      "| train_c6a31_00004 | PENDING    |                    |           32 | 2560 |   80 | 0.0069568   |           |            |                      |\n",
      "| train_c6a31_00005 | PENDING    |                    |           16 | 2560 |  160 | 0.000452738 |           |            |                      |\n",
      "| train_c6a31_00006 | PENDING    |                    |           64 |  640 | 1280 | 0.062483    |           |            |                      |\n",
      "| train_c6a31_00000 | TERMINATED | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  | nan       |   0.268546 |                   10 |\n",
      "| train_c6a31_00001 | TERMINATED | 169.254.255.2:2568 |           32 |  160 | 1280 | 0.000370203 |   1.61571 |   0.268546 |                   10 |\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train pid=2570)\u001b[0m [2,  2000] loss: 1.617\n",
      "== Status ==\n",
      "Current time: 2022-03-02 16:58:45 (running for 00:01:45.97)\n",
      "Memory usage on this node: 4.2/15.4 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: -1.626642759456191 | Iter 4.000: -1.6864815035531686 | Iter 2.000: -1.7703009400256844 | Iter 1.000: -1.7236350999572956\n",
      "Resources requested: 2.0/4 CPUs, 1.0/1 GPUs, 0.0/8.68 GiB heap, 0.0/4.34 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/studio-lab-user/ray_results/train_2022-03-02_16-56-59\n",
      "Number of trials: 7/7 (4 PENDING, 1 RUNNING, 2 TERMINATED)\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "| Trial name        | status     | loc                |   batch_size |   l1 |   l2 |          lr |      loss |   accuracy |   training_iteration |\n",
      "|-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------|\n",
      "| train_c6a31_00002 | RUNNING    | 169.254.255.2:2570 |            2 | 2560 |  160 | 0.000672656 |   1.60163 |   0.268546 |                    1 |\n",
      "| train_c6a31_00003 | PENDING    |                    |           64 |  320 | 1280 | 0.0123423   |           |            |                      |\n",
      "| train_c6a31_00004 | PENDING    |                    |           32 | 2560 |   80 | 0.0069568   |           |            |                      |\n",
      "| train_c6a31_00005 | PENDING    |                    |           16 | 2560 |  160 | 0.000452738 |           |            |                      |\n",
      "| train_c6a31_00006 | PENDING    |                    |           64 |  640 | 1280 | 0.062483    |           |            |                      |\n",
      "| train_c6a31_00000 | TERMINATED | 169.254.255.2:2569 |            2 |   40 |  320 | 0.00840225  | nan       |   0.268546 |                   10 |\n",
      "| train_c6a31_00001 | TERMINATED | 169.254.255.2:2568 |           32 |  160 | 1280 | 0.000370203 |   1.61571 |   0.268546 |                   10 |\n",
      "+-------------------+------------+--------------------+--------------+------+------+-------------+-----------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_c6a31_00002:\n",
      "  accuracy: 0.2685459940652819\n",
      "  date: 2022-03-02_16-58-48\n",
      "  done: false\n",
      "  experiment_id: 2061c12ba09248cf9e2c8d21070d041e\n",
      "  hostname: default\n",
      "  iterations_since_restore: 2\n",
      "  loss: 1.5795485253503838\n",
      "  node_ip: 169.254.255.2\n",
      "  pid: 2570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 30.04633092880249\n",
      "  time_this_iter_s: 12.668813228607178\n",
      "  time_total_s: 30.04633092880249\n",
      "  timestamp: 1646240328\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: c6a31_00002\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def main(num_samples=7, max_num_epochs=10, gpus_per_trial=2):\n",
    "    #data_dir = os.path.abspath(\"./data\")\n",
    "    #load_data(data_dir)\n",
    "    config = {\n",
    "        \"l1\": tune.sample_from(lambda _: 10*2**np.random.randint(2, 9)),\n",
    "        \"l2\": tune.sample_from(lambda _: 10*2**np.random.randint(2, 9)),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([2, 16, 32, 64])\n",
    "    }\n",
    "    #print(config)\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    #print(scheduler)\n",
    "    \n",
    "    reporter = CLIReporter(\n",
    "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    #print(reporter)\n",
    "\n",
    "    #reporter(timesteps_total=1)\n",
    "     \n",
    "    result = tune.run(\n",
    "        #partial(train, data_dir=PATH),\n",
    "        train,\n",
    "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    main(num_samples=num_classes, max_num_epochs=100, gpus_per_trial=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35393f-ff3e-43ee-99ec-f4c06fdc7a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fed1a9-9511-44ff-8cf3-181be0bb0fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env:Python",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
