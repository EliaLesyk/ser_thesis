{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe16bdba-50af-46a9-8ae4-b29ea35cd3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from time import gmtime, strftime, time\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "# from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "# from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be749834-97af-44c7-af35-d413922bcda8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## With WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3735eba0-f4a4-4cc7-9ec5-a6d0b5862138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=73):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    t.manual_seed(seed)\n",
    "    t.cuda.manual_seed(seed)\n",
    "    t.cuda.manual_seed_all(seed)\n",
    "    # some cudnn methods can be random even after fixing the seed unless you tell it to be deterministic\n",
    "    t.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d37617-d695-4270-bbec-9fa48a568c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_NOTEBOOK_NAME='w2v'\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_NOTEBOOK_NAME='w2v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d27439-f542-4612-bc44-7e3e4bfe3103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33melliel\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cd3863-2c88-484f-95d7-e1a9f8d30018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ksqmd2i3\n",
      "Sweep URL: https://wandb.ai/elliel/w2v_aibo/sweeps/ksqmd2i3\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random', #grid, random, bayesian\n",
    "    'metric': {\n",
    "      #'name': 'auc_score',\n",
    "      'name': 'f1_score',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "\n",
    "        'learning_rate': {\n",
    "            'values': [5e-5, 3e-5]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [32, 64]\n",
    "        },\n",
    "        'epochs':{'value': 10}\n",
    "        #'dropout':{\n",
    "         #   'values': [0.3, 0.4, 0.5]\n",
    "        #},\n",
    "        #'tokenizer_max_len': {'value': 40},\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_defaults = {\n",
    "    'learning_rate': 3e-5,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 10\n",
    "    #'dropout': 0.3,\n",
    "    #'tokenizer_max_len': 40\n",
    "}\n",
    "\n",
    "#wandb.init(project=\"w2v_aibo\")\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"w2v_aibo\", entity=\"elliel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "698f809e-9fbc-45a6-95fa-c97fc5c5c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(preds, labels):\n",
    "    #preds = t.from_numpy(preds)\n",
    "    print(\"t to np\", preds.dtype)\n",
    "    #labels = t.from_numpy(labels)\n",
    "    \n",
    "    preds = np.stack(preds)\n",
    "    print(\"preds stack\", preds.dtype)\n",
    "    #preds = preds.cpu().detach().numpy()\n",
    "    #print(\"t to np\", preds.dtype)\n",
    "    labels = np.stack(labels)\n",
    "    #labels = labels.cpu().detach().numpy()\n",
    "    \n",
    "    \n",
    "    auc_micro_list = []\n",
    "    for i in range(n_labels):\n",
    "      current_pred = preds.T[i]\n",
    "      current_label = labels.T[i]\n",
    "      fpr_micro, tpr_micro, _ = metrics.roc_curve(current_label.T, current_pred.T)\n",
    "      auc_micro = metrics.auc(fpr_micro, tpr_micro)\n",
    "      auc_micro_list.append(auc_micro)\n",
    "    \n",
    "    return {\"auc\": np.array(auc_micro).mean()}\n",
    "    \n",
    "\n",
    "    #fpr_micro, tpr_micro, _ = metrics.roc_curve(labels.ravel(), preds.ravel())\n",
    "    \n",
    "    #auc_micro = metrics.auc(fpr_micro, tpr_micro)\n",
    "    #return {\"auc_micro\": auc_micro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d1ee0-0ede-4078-b967-711b8159b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        #train_dataset, valid_dataset = build_dataset(config.tokenizer_max_len)\n",
    "        #train_data_loader, valid_data_loader = build_dataloader(train_dataset, valid_dataset, config.batch_size)\n",
    "        #print(\"Length of Train Dataloader: \", len(train_data_loader))\n",
    "        #print(\"Length of Valid Dataloader: \", len(valid_data_loader))\n",
    "\n",
    "        device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "\n",
    "        #n_train_steps = int(len(train_dataset) / config.batch_size * 10)\n",
    "\n",
    "        #model = ret_model(n_train_steps, config.dropout)\n",
    "        #optimizer = ret_optimizer(model)\n",
    "        #scheduler = ret_scheduler(optimizer, n_train_steps)\n",
    "        #model.to(device)\n",
    "\n",
    "        \n",
    "        n_epochs = config.epochs\n",
    "\n",
    "        #best_val_loss = 100\n",
    "        #for epoch in tqdm(range(n_epochs)):\n",
    "         #   train_loss = train_fn(train_data_loader, model, optimizer, device, scheduler)\n",
    "         #   eval_loss, preds, labels = eval_fn(valid_data_loader, model, device)\n",
    "          \n",
    "         #   auc_score = log_metrics(preds, labels)[\"auc_micro\"]\n",
    "         #   print(\"AUC score: \", auc_score)\n",
    "         #   avg_train_loss, avg_val_loss = train_loss / len(train_data_loader), eval_loss / len(valid_data_loader)\n",
    "         #   wandb.log({\n",
    "          #      \"epoch\": epoch + 1,\n",
    "          #      \"train_loss\": avg_train_loss,\n",
    "          #      \"val_loss\": avg_val_loss,\n",
    "          #      \"auc_score\": auc_score,\n",
    "          #  })\n",
    "           # print(\"Average Train loss: \", avg_train_loss)\n",
    "           # print(\"Average Valid loss: \", avg_val_loss)\n",
    "\n",
    "            #if avg_val_loss < best_val_loss:\n",
    "             #   best_val_loss = avg_val_loss\n",
    "              #  torch.save(model.state_dict(), \"./best_model.pt\")  \n",
    "               # print(\"Model saved as current val_loss is: \", best_val_loss)  \n",
    "        \n",
    "        \n",
    "        train_dataset = TensorDataset(t.tensor(x_train), t.tensor(y_train))\n",
    "        # train_dataset = TensorDataset(torch.from_numpy(x_train_eval).float(), torch.from_numpy(y_train_eval).float())\n",
    "        val_dataset = TensorDataset(t.tensor(x_val), t.tensor(y_val))\n",
    "        test_dataset = TensorDataset(t.tensor(x_test), t.tensor(y_test))\n",
    "\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True) # num_workers\n",
    "        val_loader = DataLoader(dataset=val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(dataset=test_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "        \n",
    "        #model = MLP(6144, 3000, 1000, 7)\n",
    "        model = MLP(512, 3000, 1000, 7)\n",
    "        #print(model)\n",
    "        model = nn.DataParallel(model)\n",
    "        wandb.watch(model)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # set up the optimizer\n",
    "        optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0)\n",
    "\n",
    "        trainer = Trainer(model, \"w2v\", \"aibo\", criterion, optimizer, train_loader, val_loader, test_loader, \n",
    "                          cuda=t.cuda.is_available(),\\\n",
    "                          early_stopping_patience=20)\n",
    "\n",
    "        # go, go, go... call fit on trainer\n",
    "        res = trainer.fit(100)\n",
    "        wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7056e9a6-ffc6-48f2-9daa-d3bf5fa12195",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,  # Model to be trained.\n",
    "                 model_name,\n",
    "                 dataset,\n",
    "                 crit,  # Loss function\n",
    "                 optim=None,  # Optimizer\n",
    "                 train_dl=None,  # Training data set\n",
    "                 val_test_dl=None,  # Validation data set\n",
    "                 test_dl=None,  # Test data set\n",
    "                 cuda=True,  # Whether to use the GPU\n",
    "                 early_stopping_patience=-1):   # The patience for early stopping\n",
    "                 #unsqueeze_needed=True\n",
    "        self._model = model\n",
    "        self.model_name = model_name\n",
    "        self.dataset = dataset\n",
    "        self._crit = crit\n",
    "        self._optim = optim\n",
    "        self._train_dl = train_dl\n",
    "        self._val_test_dl = val_test_dl\n",
    "        self._test_dl = test_dl\n",
    "        self._cuda = cuda\n",
    "        self._early_stopping_patience = early_stopping_patience\n",
    "        #self._unsqueeze_needed = unsqueeze_needed\n",
    "        \n",
    "\n",
    "        if cuda:\n",
    "            self._model = model.cuda()\n",
    "            self._crit = crit.cuda()\n",
    "\n",
    "    #def save_checkpoint(self, epoch):\n",
    "     #   t.save({'state_dict': self._model.state_dict()}, 'checkpoints/checkpoint_{:03d}.ckp'.format(epoch))\n",
    "\n",
    "    #def restore_checkpoint(self, epoch_n):\n",
    "    def restore_checkpoint(self):\n",
    "        path = 'checkpoints/' + self.model_name + '_checkpoint_{}.ckp'.format(get_datetime())\n",
    "        if os.path.exists(path):\n",
    "            #ckp = t.load('checkpoints/checkpoint_{:03d}.ckp'.format(epoch_n), 'cuda' if self._cuda else None)\n",
    "            ckp = t.load(path, 'cuda' if self._cuda else None)\n",
    "            self._model.load_state_dict(ckp['state_dict'])\n",
    "\n",
    "    def save_onnx(self, fn):\n",
    "        m = self._model.cpu()\n",
    "        m.eval()\n",
    "        x = t.randn(1, 3, 300, 300, requires_grad=True)\n",
    "        y = self._model(x)\n",
    "        t.onnx.export(m,  # model being run\n",
    "                      x,  # model input (or a tuple for multiple inputs)\n",
    "                      fn,  # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,  # store the trained parameter weights inside the model file\n",
    "                      opset_version=10,  # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names=['input'],  # the model's input names\n",
    "                      output_names=['output'],  # the model's output names\n",
    "                      dynamic_axes={'input': {0: 'batch_size'},  # variable lenght axes\n",
    "                                    'output': {0: 'batch_size'}})\n",
    "\n",
    "    def train_step(self, x, y):\n",
    "        # perform following steps:\n",
    "        # -reset the gradients / clear the gradients of all optimized variables\n",
    "        self._optim.zero_grad()\n",
    "        # -propagate through the network / forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = self._model.forward(x)\n",
    "        # -calculate the loss\n",
    "        loss = self._crit(output, y)\n",
    "        # -compute gradient by backprop / backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # -update weights / perform a single optimization step (parameter update)\n",
    "        self._optim.step()\n",
    "        # -return the loss\n",
    "        return loss, output\n",
    "\n",
    "    def val_test_step(self, x, y):\n",
    "        # predict\n",
    "        # propagate through the network and calculate the loss and predictions\n",
    "        pred = self._model.forward(x)\n",
    "        # calculate the loss\n",
    "        loss = self._crit(pred, y)\n",
    "        # return the loss and the predictions\n",
    "        return loss, pred\n",
    "\n",
    "    def train_epoch(self):\n",
    "        # set training mode / prepare model for training\n",
    "        self._model.train()\n",
    "        # iterate through the training set\n",
    "        # clear lists to track next epoch\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for x, y in self._train_dl:\n",
    "            # transfer the batch to \"cuda()\" -> the gpu if a gpu is given\n",
    "            if self._cuda:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "           # if self._unsqueeze_needed:\n",
    "            #    x = x.unsqueeze(1)\n",
    "            # perform a training step\n",
    "            loss, pred = self.train_step(x, y)\n",
    "            total_loss += loss.item()\n",
    "            #total_acc += accuracy_score(y.cpu().detach().numpy(), np.hstack(pred))\n",
    "            #total_acc += accuracy_score(y.cpu(), pred.cpu() > 0.5)\n",
    "        # calculate the average loss for the epoch and return it\n",
    "        total_loss = total_loss / len(self._train_dl)\n",
    "        #total_acc = total_acc / len(self._train_dl)\n",
    "        #print(\"Train: loss: {}, accuracy: {}\".format(total_loss, total_acc))\n",
    "        print(\"Train: loss: {}\".format(total_loss))\n",
    "        return total_loss\n",
    "\n",
    "    def val_test(self, test=False):\n",
    "        # set eval mode / prepare model for evaluation\n",
    "        self._model.eval()\n",
    "        # disable gradient computation (disable autograd engine)\n",
    "        with t.no_grad():\n",
    "            # iterate through the validation set\n",
    "            # clear lists to track next epoch\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            total_f1 = 0\n",
    "            if test:\n",
    "                dataset = self._test_dl\n",
    "            else:\n",
    "                dataset = self._val_test_dl\n",
    "            for x, y in dataset:\n",
    "                # transfer the batch to the gpu if given\n",
    "                if self._cuda:\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "                #if self._unsqueeze_needed:\n",
    "                 #   x = x.unsqueeze(1)\n",
    "\n",
    "                # perform a validation step / forward pass: compute predicted outputs by passing inputs to the model\n",
    "                loss, pred = self.val_test_step(x, y)       # pred.shape torch.Size([8, 5]) = bs, num_cl\n",
    "                # calculate metrics for this iteration\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # deal with multilabel\n",
    "                activation = t.nn.Softmax(dim=1)\n",
    "                pred = activation(pred.data)\n",
    "                pred = t.max(pred, 1)[1]    # choose maximum class index for the most predominant index\n",
    "                # pred: tensor([4, 3, 2, 4, 0, 3, 4, 3])\n",
    "                #pred = pred.cpu().detach()\n",
    "                pred = pred.cpu().detach().numpy()\n",
    "\n",
    "                # prepare to count predictions for each class\n",
    "                correct_pred = {classname: 0 for classname in w2v_classes}\n",
    "                total_pred = {classname: 0 for classname in w2v_classes}\n",
    "                # collect the correct predictions for each class\n",
    "                for label, prediction in zip(y, pred):\n",
    "                    if label == prediction:\n",
    "                        correct_pred[w2v_classes[label]] += 1\n",
    "                    total_pred[w2v_classes[label]] += 1\n",
    "\n",
    "                # print accuracy for each class\n",
    "                #for classname, correct_count in correct_pred.items():\n",
    "                 #   accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "                    #print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))\n",
    "                  #  print(\"Accuracy for class {} is: {} %\".format(classname, accuracy))\n",
    "\n",
    "                #total_acc += accuracy_score(y.cpu(), pred.cpu() > 0.5)\n",
    "                total_acc += accuracy_score(y.cpu().detach().numpy(), np.hstack(pred))\n",
    "                #total_f1 += f1_score(y.cpu(), pred.cpu() > 0.5, average=None)\n",
    "                total_f1 += f1_score(y.cpu().detach().numpy(), np.hstack(pred), average='weighted')\n",
    "                # save the predictions and the labels for each batch\n",
    "\n",
    "            # calculate the average loss and average metrics\n",
    "            total_loss = total_loss / len(dataset)\n",
    "            total_acc = total_acc / len(dataset)\n",
    "            total_f1 = total_f1 / len(dataset)\n",
    "             \n",
    "            # return the loss and print the calculated metrics\n",
    "            print(\"Test: loss: {}, accuracy: {}%, f-score: {}\".format(total_loss, total_acc * 100, total_f1))\n",
    "            print(\"y unique\", np.unique(y))\n",
    "            print(\"pred unique\", np.unique(pred))\n",
    "            print(classification_report(y.cpu(), pred, target_names=labels_dict.keys()))\n",
    "        t.enable_grad()\n",
    "        return total_loss, total_f1\n",
    "\n",
    "    def fit(self, n_epochs):\n",
    "        # to track the training loss as the model trains\n",
    "        #train_losses = []\n",
    "        # to track the validation loss as the model trains\n",
    "        #valid_losses = []\n",
    "        # to track the average training loss per epoch as the model trains\n",
    "        avg_train_losses = []\n",
    "        # to track the average validation loss per epoch as the model trains\n",
    "        avg_valid_losses = []\n",
    "        # store results\n",
    "        #res = open('./results/' + self.model_name + '_results.txt', 'w')\n",
    "        #res.write(50 * '=')\n",
    "        #res.write('Model \\n')\n",
    "        #res.write(str(self._model) + '\\n')\n",
    "\n",
    "        # load the last checkpoint with the best model\n",
    "        self.restore_checkpoint()\n",
    "\n",
    "        # initialize the early_stopping object\n",
    "        early_stopping = EarlyStopping(patience=self._early_stopping_patience, verbose=True)\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            # train the model\n",
    "            train_loss = self.train_epoch()\n",
    "            # validate the model\n",
    "            valid_loss, f1_score = self.val_test()\n",
    "\n",
    "            # calculate average loss over an epoch\n",
    "            #train_loss = np.average(train_losses)\n",
    "            #train_loss = train_losses / len(self._train_dl)\n",
    "            #valid_loss = np.average(valid_losses)\n",
    "            \n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": valid_loss,\n",
    "                #\"auc_score\": auc_score,\n",
    "                \"f1_score\": f1_score\n",
    "            })\n",
    "\n",
    "            avg_train_losses.append(train_loss)\n",
    "            avg_valid_losses.append(valid_loss)\n",
    "\n",
    "            \"\"\"\n",
    "            # print training/validation statistics\n",
    "            epoch_len = len(str(n_epochs))\n",
    "\n",
    "            print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                         f'train_loss: {train_loss:.5f} ' +\n",
    "                         f'valid_loss: {valid_loss:.5f}')\n",
    "\n",
    "            print(print_msg)\n",
    "            \"\"\"\n",
    "\n",
    "            # early_stopping needs the validation loss to check if it has decreased,\n",
    "            # if it has, it will make a checkpoint of the current model\n",
    "            early_stopping(valid_loss, self._model, self.model_name, self.dataset)\n",
    "\n",
    "            \"\"\"\n",
    "            # use the save_checkpoint function to save the model for each epoch\n",
    "            save_flag = self._early_stopping_cb.step(l_dev)\n",
    "\n",
    "            if save_flag:\n",
    "                res.write(50 * '=')\n",
    "                res.write('Epoch: ' + str(self.epoch) + ' Training Loss :' + str(l_train) + ' Development Loss :' + str(\n",
    "                    l_dev))\n",
    "                Trainer.save_checkpoint(self, self.epoch + 1, model_name)\n",
    "                self.epoch_n = self.epoch + 1\n",
    "            \"\"\"\n",
    "                \n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping has been reached\")\n",
    "                break\n",
    "\n",
    "            # load the last checkpoint with the best model\n",
    "            #self._model.load_state_dict(t.load('checkpoint.pt'))\n",
    "            #self.restore_checkpoint()\n",
    "        \n",
    "                #auc_score = log_metrics(preds, labels)[\"auc_micro\"]\n",
    "        #auc_score = log_metrics(pred, y)[\"auc_micro\"]\n",
    "        #print(\"AUC score: \", auc_score)\n",
    "        #avg_train_loss, avg_val_loss = train_loss / len(train_loader), eval_loss / len(val_loader)\n",
    "\n",
    "        #print(\"Average Train loss: \", avg_train_loss)\n",
    "        #print(\"Average loss: \", total_loss)\n",
    "\n",
    "        #if total_loss < best_val_loss:\n",
    "         #   best_val_loss = total_loss\n",
    "         #   t.save(model.state_dict(), \"./best_model.pt\")  \n",
    "         #   print(\"Model saved as current val_loss is: \", best_val_loss)  \n",
    "        \n",
    "        # return model, avg_train_losses, avg_valid_losses\n",
    "        #res.close()\n",
    "        return avg_train_losses, avg_valid_losses\n",
    "    \n",
    "    def test(self):\n",
    "        #avg_test_losses = []\n",
    "\n",
    "        # load the last checkpoint with the best model\n",
    "        self.restore_checkpoint()\n",
    "\n",
    "        # initialize the early_stopping object\n",
    "        #early_stopping = EarlyStopping(patience=self._early_stopping_patience, verbose=True)\n",
    "\n",
    "        # validate the model\n",
    "        test_loss = self.val_test()\n",
    "\n",
    "        # calculate average loss over an epoch\n",
    "        #train_loss = np.average(train_losses)\n",
    "        #train_loss = train_losses / len(self._train_dl)\n",
    "        #valid_loss = np.average(valid_losses)\n",
    "\n",
    "        #avg_test_losses.append(test_loss)\n",
    "\n",
    "            # early_stopping needs the validation loss to check if it has decreased,\n",
    "            # if it has, it will make a checkpoint of the current model\n",
    "            #early_stopping(test_loss, self._model, self.model_name, self.dataset)\n",
    "\n",
    "            #if early_stopping.early_stop:\n",
    "             #   print(\"Early stopping has been reached\")\n",
    "              #  break\n",
    "\n",
    "        # return model, avg_train_losses, avg_valid_losses\n",
    "        #res.close()\n",
    "        #return avg_test_losses\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e8c84-4605-4ea7-ac86-f94752e0c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, function=trainer, count=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108286fa-a26e-493f-a1fa-53a1721ebd20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c912d-add3-4759-9862-e38635599f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbd0d811-165e-43e1-b140-ca648c74e8b9",
   "metadata": {},
   "source": [
    "## Without WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10bb16c1-9288-4056-9605-bb936d882b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft_df = np.load(\"data/AIBO/w2v/\" + \"aibo_ft.npy\")\n",
    "# hs_df = np.load(\"/Users/el/embrace/data/data_wav2vec2/icp/\" + \"icp_hs.npy\")\n",
    "#labels_df = np.load(\"data/AIBO/w2v/\" + \"aibo_labels.npy\")\n",
    "\n",
    "# labels_dict = {'ang': 1, 'exc': 3, 'fea': 2, 'fru': 4, 'hap': 3, 'neu': 0, 'oth': 6, 'sad': 4, 'sur': 5, 'xxx': 6}\n",
    "labels_dict = {'A': 0, 'E': 1, 'N': 2, 'P': 3, 'R': 4}\n",
    "ID_TO_CLASS = {v: k for k, v in labels_dict.items()}\n",
    "w2v_classes = list(ID_TO_CLASS.keys())\n",
    "\n",
    "#lb_df = np.array([labels_dict[letter] for letter in labels_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3174d84c-aaab-4b48-a015-d69af9aa79f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "453c5fd5-0993-4063-97d3-61842440af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee309e5e-3aa1-4626-8925-f31008eb3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'xvec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd7ab4df-c235-4479-b8a9-b9a626f662da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3139,) (84,) (102,)\n",
      "(3139, 512) (84, 512) (102, 512)\n"
     ]
    }
   ],
   "source": [
    "PATH = \"data/AIBO/wav2vec/\"\n",
    "\n",
    "x_train = np.load(PATH + model + \"_aibo_ft_train.npy\")\n",
    "x_val = np.load(PATH + model + \"_aibo_ft_val.npy\")\n",
    "x_test = np.load(PATH + model + \"_aibo_ft_test.npy\")\n",
    "\n",
    "y_train = np.load(PATH + model + \"_aibo_lb_train.npy\", allow_pickle=True)\n",
    "y_val = np.load(PATH + model + \"_aibo_lb_val.npy\", allow_pickle=True)\n",
    "y_test = np.load(PATH + model + \"_aibo_lb_test.npy\", allow_pickle=True)\n",
    "\n",
    "print(y_train.shape, y_val.shape, y_test.shape)       # (4696,) (935,) (1407,)\n",
    "print(x_train.shape, x_val.shape, x_test.shape)       # (4696, 3072) (935, 3072) (1407, 3072)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebc00dff-97c6-4547-9563-39f4b46e3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(t.tensor(x_train), t.tensor(y_train))\n",
    "# train_dataset = TensorDataset(torch.from_numpy(x_train_eval).float(), torch.from_numpy(y_train_eval).float())\n",
    "val_dataset = TensorDataset(t.tensor(x_val), t.tensor(y_val))\n",
    "test_dataset = TensorDataset(t.tensor(x_test), t.tensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True) # num_workers\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "196d19a0-145e-4ce0-8073-ec72f6e17c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A', 'E', 'N', 'P', 'R'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42388a35-44d4-4654-8016-9575ef96d957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7993694b-259e-4e5d-a65a-4fc53f3f08df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9a4edfa-e2e5-480e-82b0-4954bd187c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_x = ft_df\n",
    "#my_y = lb_df\n",
    "\n",
    "#split_index = int(my_y.shape[0]*0.8)\n",
    "#print(split_index)\n",
    "\n",
    "#all_indexes = list(range(my_x.shape[0]))\n",
    "#test_indexes = all_indexes[(split_index + 1):]\n",
    "#x_test = my_x[test_indexes]\n",
    "#y_test = my_y[test_indexes]\n",
    "\n",
    "#train_indexes = all_indexes[:(split_index + 1)]\n",
    "#x_train = my_x[train_indexes]\n",
    "#y_train = my_y[train_indexes]\n",
    "\n",
    "#eval_split_index = 934\n",
    "#all_indexes = list(range(x_train.shape[0]))\n",
    "#eval_indexes = all_indexes[(eval_split_index + 1):]\n",
    "#eval_train_indexes = all_indexes[:(eval_split_index + 1)]\n",
    "\n",
    "#x_train_eval = x_train[eval_indexes]\n",
    "#y_train_eval = y_train[eval_indexes]\n",
    "#x_eval = x_train[eval_train_indexes]\n",
    "#y_eval = y_train[eval_train_indexes]\n",
    "\n",
    "# x_train_eval=np.vstack(x_train_eval).astype(np.float)\n",
    "# y_train_eval=np.vstack(y_train_eval).astype(np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca952110-e687-4d1f-bc4e-baed2ce80523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_train_eval.shape, y_eval.shape, y_test.shape)       # (4696,) (935,) (1407,)\n",
    "#print(x_train_eval.shape, x_eval.shape, x_test.shape)       # (4696, 3072) (935, 3072) (1407, 3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "016ab04a-7051-4953-a85d-43527e6fb446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if t.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    else:\n",
    "        return \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e6314da-56ea-4d8a-9c14-5775283e3fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A', 'E', 'N', 'P', 'R'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "875b24d9-d68b-4665-a6f3-999b745c93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,  # Model to be trained.\n",
    "                 model_name,\n",
    "                 dataset,\n",
    "                 crit,  # Loss function\n",
    "                 optim=None,  # Optimizer\n",
    "                 train_dl=None,  # Training data set\n",
    "                 val_test_dl=None,  # Validation data set\n",
    "                 test_dl=None,  # Test data set\n",
    "                 cuda=True,  # Whether to use the GPU\n",
    "                 early_stopping_patience=-1):   # The patience for early stopping\n",
    "                 #unsqueeze_needed=True\n",
    "        self._model = model\n",
    "        self.model_name = model_name\n",
    "        self.dataset = dataset\n",
    "        self._crit = crit\n",
    "        self._optim = optim\n",
    "        self._train_dl = train_dl\n",
    "        self._val_test_dl = val_test_dl\n",
    "        self._test_dl = test_dl\n",
    "        self._cuda = cuda\n",
    "        self._early_stopping_patience = early_stopping_patience\n",
    "        #self._unsqueeze_needed = unsqueeze_needed\n",
    "        \n",
    "\n",
    "        if cuda:\n",
    "            self._model = model.cuda()\n",
    "            self._crit = crit.cuda()\n",
    "\n",
    "    #def save_checkpoint(self, epoch):\n",
    "     #   t.save({'state_dict': self._model.state_dict()}, 'checkpoints/checkpoint_{:03d}.ckp'.format(epoch))\n",
    "\n",
    "    #def restore_checkpoint(self, epoch_n):\n",
    "    def restore_checkpoint(self):\n",
    "        path = 'checkpoints/' + self.model_name + '_checkpoint_{}.ckp'.format(get_datetime())\n",
    "        if os.path.exists(path):\n",
    "            #ckp = t.load('checkpoints/checkpoint_{:03d}.ckp'.format(epoch_n), 'cuda' if self._cuda else None)\n",
    "            ckp = t.load(path, 'cuda' if self._cuda else None)\n",
    "            self._model.load_state_dict(ckp['state_dict'])\n",
    "\n",
    "    def save_onnx(self, fn):\n",
    "        m = self._model.cpu()\n",
    "        m.eval()\n",
    "        x = t.randn(1, 3, 300, 300, requires_grad=True)\n",
    "        y = self._model(x)\n",
    "        t.onnx.export(m,  # model being run\n",
    "                      x,  # model input (or a tuple for multiple inputs)\n",
    "                      fn,  # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,  # store the trained parameter weights inside the model file\n",
    "                      opset_version=10,  # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names=['input'],  # the model's input names\n",
    "                      output_names=['output'],  # the model's output names\n",
    "                      dynamic_axes={'input': {0: 'batch_size'},  # variable lenght axes\n",
    "                                    'output': {0: 'batch_size'}})\n",
    "\n",
    "    def train_step(self, x, y):\n",
    "        # perform following steps:\n",
    "        # -reset the gradients / clear the gradients of all optimized variables\n",
    "        self._optim.zero_grad()\n",
    "        # -propagate through the network / forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = self._model.forward(x)\n",
    "        # -calculate the loss\n",
    "        loss = self._crit(output, y)\n",
    "        # -compute gradient by backprop / backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # -update weights / perform a single optimization step (parameter update)\n",
    "        self._optim.step()\n",
    "        # -return the loss\n",
    "        return loss, output\n",
    "\n",
    "    def val_test_step(self, x, y):\n",
    "        # predict\n",
    "        # propagate through the network and calculate the loss and predictions\n",
    "        pred = self._model.forward(x)\n",
    "        # calculate the loss\n",
    "        loss = self._crit(pred, y)\n",
    "        # return the loss and the predictions\n",
    "        return loss, pred\n",
    "\n",
    "    def train_epoch(self):\n",
    "        # set training mode / prepare model for training\n",
    "        self._model.train()\n",
    "        # iterate through the training set\n",
    "        # clear lists to track next epoch\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for x, y in self._train_dl:\n",
    "            # transfer the batch to \"cuda()\" -> the gpu if a gpu is given\n",
    "            if self._cuda:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "           # if self._unsqueeze_needed:\n",
    "            #    x = x.unsqueeze(1)\n",
    "            # perform a training step\n",
    "            loss, pred = self.train_step(x, y)\n",
    "            total_loss += loss.item()\n",
    "            #total_acc += accuracy_score(y.cpu().detach().numpy(), np.hstack(pred))\n",
    "            #total_acc += accuracy_score(y.cpu(), pred.cpu() > 0.5)\n",
    "        # calculate the average loss for the epoch and return it\n",
    "        total_loss = total_loss / len(self._train_dl)\n",
    "        #total_acc = total_acc / len(self._train_dl)\n",
    "        #print(\"Train: loss: {}, accuracy: {}\".format(total_loss, total_acc))\n",
    "        print(\"Train: loss: {}\".format(total_loss))\n",
    "        return total_loss\n",
    "\n",
    "    def val_test(self, test=False):\n",
    "        # set eval mode / prepare model for evaluation\n",
    "        self._model.eval()\n",
    "        # disable gradient computation (disable autograd engine)\n",
    "        with t.no_grad():\n",
    "            # iterate through the validation set\n",
    "            # clear lists to track next epoch\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            total_f1 = 0\n",
    "            if test:\n",
    "                dataset = self._test_dl\n",
    "            else:\n",
    "                dataset = self._val_test_dl\n",
    "            for x, y in dataset:\n",
    "                # transfer the batch to the gpu if given\n",
    "                if self._cuda:\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "                #if self._unsqueeze_needed:\n",
    "                 #   x = x.unsqueeze(1)\n",
    "\n",
    "                # perform a validation step / forward pass: compute predicted outputs by passing inputs to the model\n",
    "                loss, pred = self.val_test_step(x, y)       # pred.shape torch.Size([8, 5]) = bs, num_cl\n",
    "                # calculate metrics for this iteration\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # deal with multilabel\n",
    "                activation = t.nn.Softmax(dim=1)\n",
    "                pred = activation(pred.data)\n",
    "                pred = t.max(pred, 1)[1]    # choose maximum class index for the most predominant index\n",
    "                # pred: tensor([4, 3, 2, 4, 0, 3, 4, 3])\n",
    "                #pred = pred.cpu().detach()\n",
    "                pred = pred.cpu().detach().numpy()\n",
    "\n",
    "                # prepare to count predictions for each class\n",
    "                correct_pred = {classname: 0 for classname in w2v_classes}\n",
    "                total_pred = {classname: 0 for classname in w2v_classes}\n",
    "                # collect the correct predictions for each class\n",
    "                for label, prediction in zip(y, pred):\n",
    "                    if label == prediction:\n",
    "                        correct_pred[w2v_classes[label]] += 1\n",
    "                    total_pred[w2v_classes[label]] += 1\n",
    "\n",
    "                # print accuracy for each class\n",
    "                #for classname, correct_count in correct_pred.items():\n",
    "                 #   accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "                    #print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))\n",
    "                  #  print(\"Accuracy for class {} is: {} %\".format(classname, accuracy))\n",
    "\n",
    "                #total_acc += accuracy_score(y.cpu(), pred.cpu() > 0.5)\n",
    "                total_acc += accuracy_score(y.cpu().detach().numpy(), np.hstack(pred))\n",
    "                #total_f1 += f1_score(y.cpu(), pred.cpu() > 0.5, average=None)\n",
    "                total_f1 += f1_score(y.cpu().detach().numpy(), np.hstack(pred), average='weighted')\n",
    "                # save the predictions and the labels for each batch\n",
    "\n",
    "            # calculate the average loss and average metrics\n",
    "            total_loss = total_loss / len(dataset)\n",
    "            total_acc = total_acc / len(dataset)\n",
    "            total_f1 = total_f1 / len(dataset)\n",
    "             \n",
    "            # return the loss and print the calculated metrics\n",
    "            print(\"Test: loss: {}, accuracy: {}%, f-score: {}\".format(total_loss, total_acc * 100, total_f1))\n",
    "            print(\"y unique\", t.unique(y))\n",
    "            print(\"pred unique\", np.unique(pred))\n",
    "            #print(classification_report(y.cpu(), pred, target_names=labels_dict.keys()))\n",
    "            print(classification_report(y.cpu(), pred, target_names=t.unique(y)))\n",
    "        t.enable_grad()\n",
    "        return total_loss, total_f1\n",
    "\n",
    "    def fit(self, n_epochs):\n",
    "        # to track the training loss as the model trains\n",
    "        #train_losses = []\n",
    "        # to track the validation loss as the model trains\n",
    "        #valid_losses = []\n",
    "        # to track the average training loss per epoch as the model trains\n",
    "        avg_train_losses = []\n",
    "        # to track the average validation loss per epoch as the model trains\n",
    "        avg_valid_losses = []\n",
    "        # store results\n",
    "        #res = open('./results/' + self.model_name + '_results.txt', 'w')\n",
    "        #res.write(50 * '=')\n",
    "        #res.write('Model \\n')\n",
    "        #res.write(str(self._model) + '\\n')\n",
    "\n",
    "        # load the last checkpoint with the best model\n",
    "        self.restore_checkpoint()\n",
    "\n",
    "        # initialize the early_stopping object\n",
    "        early_stopping = EarlyStopping(patience=self._early_stopping_patience, verbose=True)\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            # train the model\n",
    "            train_loss = self.train_epoch()\n",
    "            # validate the model\n",
    "            valid_loss, f1_score = self.val_test()\n",
    "\n",
    "            # calculate average loss over an epoch\n",
    "            #train_loss = np.average(train_losses)\n",
    "            #train_loss = train_losses / len(self._train_dl)\n",
    "            #valid_loss = np.average(valid_losses)\n",
    "\n",
    "            avg_train_losses.append(train_loss)\n",
    "            avg_valid_losses.append(valid_loss)\n",
    "\n",
    "            \"\"\"\n",
    "            # print training/validation statistics\n",
    "            epoch_len = len(str(n_epochs))\n",
    "\n",
    "            print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                         f'train_loss: {train_loss:.5f} ' +\n",
    "                         f'valid_loss: {valid_loss:.5f}')\n",
    "\n",
    "            print(print_msg)\n",
    "            \"\"\"\n",
    "\n",
    "            # early_stopping needs the validation loss to check if it has decreased,\n",
    "            # if it has, it will make a checkpoint of the current model\n",
    "            early_stopping(valid_loss, self._model, self.model_name, self.dataset)\n",
    "\n",
    "            \"\"\"\n",
    "            # use the save_checkpoint function to save the model for each epoch\n",
    "            save_flag = self._early_stopping_cb.step(l_dev)\n",
    "\n",
    "            if save_flag:\n",
    "                res.write(50 * '=')\n",
    "                res.write('Epoch: ' + str(self.epoch) + ' Training Loss :' + str(l_train) + ' Development Loss :' + str(\n",
    "                    l_dev))\n",
    "                Trainer.save_checkpoint(self, self.epoch + 1, model_name)\n",
    "                self.epoch_n = self.epoch + 1\n",
    "            \"\"\"\n",
    "                \n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping has been reached\")\n",
    "                break\n",
    "\n",
    "            # load the last checkpoint with the best model\n",
    "            #self._model.load_state_dict(t.load('checkpoint.pt'))\n",
    "            #self.restore_checkpoint()\n",
    "        \n",
    "                #auc_score = log_metrics(preds, labels)[\"auc_micro\"]\n",
    "        #auc_score = log_metrics(pred, y)[\"auc_micro\"]\n",
    "        #print(\"AUC score: \", auc_score)\n",
    "        #avg_train_loss, avg_val_loss = train_loss / len(train_loader), eval_loss / len(val_loader)\n",
    "\n",
    "        #print(\"Average Train loss: \", avg_train_loss)\n",
    "        #print(\"Average loss: \", total_loss)\n",
    "\n",
    "        #if total_loss < best_val_loss:\n",
    "         #   best_val_loss = total_loss\n",
    "         #   t.save(model.state_dict(), \"./best_model.pt\")  \n",
    "         #   print(\"Model saved as current val_loss is: \", best_val_loss)  \n",
    "        \n",
    "        # return model, avg_train_losses, avg_valid_losses\n",
    "        #res.close()\n",
    "        return avg_train_losses, avg_valid_losses\n",
    "    \n",
    "    def test(self):\n",
    "        #avg_test_losses = []\n",
    "\n",
    "        # load the last checkpoint with the best model\n",
    "        self.restore_checkpoint()\n",
    "\n",
    "        # initialize the early_stopping object\n",
    "        #early_stopping = EarlyStopping(patience=self._early_stopping_patience, verbose=True)\n",
    "\n",
    "        # validate the model\n",
    "        test_loss = self.val_test()\n",
    "\n",
    "        # calculate average loss over an epoch\n",
    "        #train_loss = np.average(train_losses)\n",
    "        #train_loss = train_losses / len(self._train_dl)\n",
    "        #valid_loss = np.average(valid_losses)\n",
    "\n",
    "        #avg_test_losses.append(test_loss)\n",
    "\n",
    "            # early_stopping needs the validation loss to check if it has decreased,\n",
    "            # if it has, it will make a checkpoint of the current model\n",
    "            #early_stopping(test_loss, self._model, self.model_name, self.dataset)\n",
    "\n",
    "            #if early_stopping.early_stop:\n",
    "             #   print(\"Early stopping has been reached\")\n",
    "              #  break\n",
    "\n",
    "        # return model, avg_train_losses, avg_valid_losses\n",
    "        #res.close()\n",
    "        #return avg_test_losses\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8973642-b64e-4e08-bfe7-5468ca267965",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    # https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, epoch=-1, verbose=False, delta=0, trace_func=print):\n",
    "    #def __init__(self, patience=7, epoch=0, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.epoch = epoch\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model, model_name, dataset):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, model_name, dataset)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                print(\"EarlyStopping counter is higher than patience\")\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, model_name, dataset)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, model_name, dataset):\n",
    "        \"\"\"\n",
    "        Saves model when validation loss decreases\n",
    "        \"\"\"\n",
    "        if not os.path.isdir('./checkpoints/'):\n",
    "            os.makedirs('./checkpoints/')\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        #a.save(model.state_dict(), self.path)\n",
    "        path = 'checkpoints/' + model_name + dataset + '_checkpoint_{}.ckp'.format(get_datetime())\n",
    "        t.save({'state_dict': model.state_dict()}, path)\n",
    "        self.val_loss_min = val_loss\n",
    "        #t.save({'state_dict': self._model.state_dict()}, 'checkpoints/' + model_name + 'checkpoint.ckp')\n",
    "\n",
    "\n",
    "def get_datetime():\n",
    "    #return strftime(\"%Y-%m-%d_%H:%M:%S\", gmtime())\n",
    "    # storing per day to have different runs from different days\n",
    "    return strftime(\"%Y-%m-%d\", gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65cc25f1-21c5-4513-b19d-c23b7e84e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53664f11-c569-4677-a9cb-00e045aa0c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            #nn.Linear(3072, 1000),     # icp_ft.npy\n",
    "            nn.Linear(6144, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convert tensor (128, 1, 28, 28) --> (128, 1*28*28)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# defining model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim_1, hidden_dim_2, out_dim=2):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim_1 = hidden_dim_1\n",
    "        self.hidden_dim_2 = hidden_dim_2\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        ## 1st hidden layer\n",
    "        self.linear_1 = nn.Linear(self.in_dim, self.hidden_dim_1)\n",
    "        self.linear_1.weight.detach().normal_(0.0, 0.1)\n",
    "        self.linear_1.bias.detach().zero_()\n",
    "        self.linear_1_bn = nn.BatchNorm1d(self.hidden_dim_1, momentum=0.6)\n",
    "\n",
    "        ## 2nd hidden layer\n",
    "        self.linear_2 = nn.Linear(self.hidden_dim_1, self.hidden_dim_2)\n",
    "        self.linear_2.weight.detach().normal_(0.0, 0.1)\n",
    "        self.linear_2.bias.detach().zero_()\n",
    "        self.linear_2_bn = nn.BatchNorm1d(self.hidden_dim_2, momentum=0.6)\n",
    "\n",
    "        ## Out layer\n",
    "        self.linear_out = nn.Linear(self.hidden_dim_2, self.out_dim)\n",
    "        self.linear_out.weight.detach().normal_(0.0, 0.1)\n",
    "        self.linear_out.bias.detach().zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear_1(x)\n",
    "        out = self.linear_1_bn(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.linear_2(out)\n",
    "        out = self.linear_2_bn(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=0.175, training=self.training)\n",
    "\n",
    "        out = self.linear_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd00ab98-88ec-450a-8eaf-456f1f637c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3139, 512)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9bf0e1b-ddde-4ec3-8f95-4ec05bd2a0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear_1): Linear(in_features=512, out_features=3000, bias=True)\n",
      "  (linear_1_bn): BatchNorm1d(3000, eps=1e-05, momentum=0.6, affine=True, track_running_stats=True)\n",
      "  (linear_2): Linear(in_features=3000, out_features=1000, bias=True)\n",
      "  (linear_2_bn): BatchNorm1d(1000, eps=1e-05, momentum=0.6, affine=True, track_running_stats=True)\n",
      "  (linear_out): Linear(in_features=1000, out_features=7, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m MLP(\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3000\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[0;32m----> 4\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# set up the optimizer\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.8/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 49\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_1_bn(out)\n\u001b[1;32m     51\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1120\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1120\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.8/site-packages/torch/nn/functional.py:1848\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1848\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_mm)"
     ]
    }
   ],
   "source": [
    "#model = MLP(6144, 3000, 1000, 7)\n",
    "model = MLP(512, 3000, 1000, 7)\n",
    "print(model)\n",
    "#ummary(model, (64, 512))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# set up the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0)\n",
    "\n",
    "trainer = Trainer(model, \"w2v\", \"aibo\", criterion, optimizer, train_loader, val_loader, test_loader, \n",
    "                  cuda=t.cuda.is_available(),\\\n",
    "                  early_stopping_patience=20)\n",
    "\n",
    "# go, go, go... call fit on trainer\n",
    "res = trainer.fit(100)\n",
    "\n",
    "# plot the results\n",
    "plt.plot(np.arange(len(res[0])), res[0], label='train loss')\n",
    "plt.plot(np.arange(len(res[1])), res[1], label='val loss')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.savefig('{}_losses_{}.png'.format(\"aibo\", \"w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "574aa1eb-7f2c-4b11-8101-4ad6de33f8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting testing\n",
      "Test: loss: 1.8888876736164093, accuracy: 61.71875%, f-score: 0.5146918113039609\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting testing\")\n",
    "test_res = trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b6210d-7d7d-4413-bfc1-7b5d184ae12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84814915-20e2-46be-8d3b-74343e49f71c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env:Python",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
